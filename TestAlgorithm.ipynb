{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Algorithms \n",
    "\n",
    "1) Иерархическая кластеризация \n",
    "2) К — средних\n",
    "3) DBSCAN\n",
    "4) Разделения смеси гауссиан (EM). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "import os\n",
    "import random as rn \n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "SEED = 32 \n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tensorflow.random.set_seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load processed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_ = np.load('data_x_50.npy') \n",
    "#Y_ = np.load('data_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch 20 news groups\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42) \n",
    "data_test = fetch_20newsgroups(subset='test',  shuffle=True, random_state=42)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = data_train.target, data_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.93 s, sys: 9.32 ms, total: 3.94 s\n",
      "Wall time: 3.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "X_test = vectorizer.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def encode_svd(x, k=50): \n",
    "    svd_model = TruncatedSVD(n_components=k, algorithm='randomized', n_iter=100, random_state=42)\n",
    "    x1 = svd_model.fit_transform(x) \n",
    "    return x1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 2min 36s, total: 4min 25s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_ = encode_svd(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 11314\n"
     ]
    }
   ],
   "source": [
    "y_train[y_train==1]\n",
    "print(len(np.unique(y_train)), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_train_[:]\n",
    "Y_ = y_train[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 50)\n",
      "(11314,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_.shape)\n",
    "print(Y_.shape)\n",
    "print(np.unique(Y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем только 10 первых классов 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5790 5790\n"
     ]
    }
   ],
   "source": [
    "yindex = Y_[Y_ < 10]\n",
    "xindex = X_[Y_ < 10]\n",
    "print(len(xindex), len(yindex))\n",
    "X_ = xindex\n",
    "Y_ = yindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "def test_cluster(x,y, model):   \n",
    "    model.fit(x)\n",
    "    labels = model.labels_\n",
    "    \n",
    "    scores = []\n",
    "    scores.append(metrics.homogeneity_score(y, labels))\n",
    "    scores.append(metrics.completeness_score(y, labels))\n",
    "    scores.append(metrics.v_measure_score(y, labels))\n",
    "    scores.append(metrics.adjusted_rand_score(y, labels))\n",
    "    scores.append(metrics.adjusted_mutual_info_score(y, labels,\n",
    "                                               average_method='arithmetic'))\n",
    "    try:\n",
    "        scores.append(metrics.silhouette_score(x, labels, metric='sqeuclidean'))\n",
    "    except ValueError:\n",
    "        scores.append(0.0)\n",
    "    scores.append(len(np.unique(labels)))\n",
    "     \n",
    "    print(\"Homogeneity: %0.3f\" %  scores[0])\n",
    "    print(\"Completeness: %0.3f\" % scores[1])\n",
    "    print(\"V-measure: %0.3f\" % scores[2])\n",
    "    print(\"Adjusted Rand Index: %0.3f\"  % scores[3])\n",
    "    print(\"Adjusted Mutual Information: %0.3f\"  % scores[4])\n",
    "    print(\"Silhouette Coefficient: %0.3f\"  % scores[5])\n",
    "    print(\"labels num: %0.3f\"  % scores[6])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготавливаем массив для хранения результатов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "n_clusters = len(np.unique(Y_))\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.430\n",
      "Completeness: 0.519\n",
      "V-measure: 0.470\n",
      "Adjusted Rand Index: 0.239\n",
      "Adjusted Mutual Information: 0.469\n",
      "Silhouette Coefficient: 0.141\n",
      "labels num: 10.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "m1 = KMeans(n_clusters=n_clusters, random_state=SEED)\n",
    "r = test_cluster(X_, Y_, m1)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vench/p37/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.hierarchical module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.292\n",
      "Completeness: 0.444\n",
      "V-measure: 0.353\n",
      "Adjusted Rand Index: 0.118\n",
      "Adjusted Mutual Information: 0.350\n",
      "Silhouette Coefficient: 0.118\n",
      "labels num: 10.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster.hierarchical import AgglomerativeClustering\n",
    "m2 = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "r = test_cluster(X_, Y_, m2)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.012\n",
      "Completeness: 0.266\n",
      "V-measure: 0.023\n",
      "Adjusted Rand Index: 0.001\n",
      "Adjusted Mutual Information: 0.018\n",
      "Silhouette Coefficient: 0.637\n",
      "labels num: 8.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "m3 = DBSCAN(eps=0.212, min_samples = 2)\n",
    "r = test_cluster(X_, Y_, m3)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.362\n",
      "Completeness: 0.402\n",
      "V-measure: 0.381\n",
      "Adjusted Rand Index: 0.243\n",
      "Adjusted Mutual Information: 0.379\n",
      "Silhouette Coefficient: -0.003\n",
      "labels num: 10.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "class GM:\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.labels_ = []\n",
    "    \n",
    "    def fit(self, x):\n",
    "        self.model.fit(x)\n",
    "        self.labels_ = self.model.predict(x)\n",
    "        \n",
    "        \n",
    "\n",
    "m4 = GaussianMixture(n_components=n_clusters)\n",
    "r = test_cluster(X_, Y_,GM(m4))\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экспериментальный алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np \n",
    "\n",
    "class Cluster:\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        ''' '''\n",
    "        self.n = n # номер класетра (начальной точки)\n",
    "        self.nodes = set([n]) # объединенные с кластером точки \n",
    "        self.join_n  = -1 # номер кластера с которым слит\n",
    "        self.dist = -1 # расстояние при слиянии (dist <= 0)\n",
    "\n",
    "    def active(self):\n",
    "        ''' '''\n",
    "        return self.join_n == -1\n",
    "        \n",
    "    def merge(self, c, dist):\n",
    "        ''' '''\n",
    "        self.nodes = self.nodes.union(c.nodes) \n",
    "        c.join_n = self.n\n",
    "        c.dist = np.abs(dist)\n",
    "        \n",
    "    def get_n(self):\n",
    "        ''' '''\n",
    "        if self.join_n == -1:\n",
    "            return self.n\n",
    "        return self.join_n\n",
    "        \n",
    "class HierarchicalClustering:\n",
    "    \n",
    "    def __init__(self, alpha = 1.01, max_iteration = 200, debug= False, delta=0., stop_neg_sum = True, betta = 2.,n_clusters=1):\n",
    "        ''' '''\n",
    "        self.alpha = alpha\n",
    "        self.betta = betta\n",
    "        self.max_iteration = max_iteration\n",
    "        self.debug = debug\n",
    "        self._c_all = []\n",
    "        self.delta = delta\n",
    "        self.stop_neg_sum = stop_neg_sum\n",
    "        self.n_clusters= n_clusters\n",
    "        self.labels_ = []\n",
    "            \n",
    "    \n",
    "    def fit(self, x, min_delta = 1.e-7):\n",
    "        ''' '''\n",
    "        self._c_all = []\n",
    "        y_ = []\n",
    "        M =  euclidean_distances(x,x)\n",
    "        C = []\n",
    "        size = len(M)\n",
    "        for i in range(size): \n",
    "            C.append( Cluster(i) )\n",
    "        \n",
    "        delta = self.delta \n",
    "        \n",
    "        for i in range(self.max_iteration): \n",
    "            d = np.min(M[M > min_delta])  * self.alpha\n",
    "            #d = self._get_min(M, C) * self.alpha\n",
    "            if d > delta:\n",
    "                delta = d  \n",
    "            #delta = delta     \n",
    "            if(self.debug): \n",
    "                print('delta: %.8f, d: %.8f' % (delta, d))    \n",
    "            M_ = M - delta\n",
    "            ''' join clusters '''\n",
    "            join = False\n",
    "        \n",
    "            for i in range(size):  \n",
    "                for j in range(i+1,size):  \n",
    "                    \n",
    "                    if(M[i][j] <= 0 or M_[i][j] > 0):\n",
    "                        continue \n",
    "                        \n",
    "                    if C[i].dist > np.abs(M_[i][j]): \n",
    "                        continue\n",
    "                        \n",
    "                    a = C[i].get_n()\n",
    "                    b = C[j].get_n() \n",
    "                    if(a == b):\n",
    "                        continue \n",
    "            \n",
    "                    C[a].merge(C[b], M_[i][j]) \n",
    "                    for s in C[b].nodes:\n",
    "                        #C[s].join_n = a\n",
    "                        C[a].merge(C[s], M_[i][j])\n",
    "                    join = True        \n",
    "            if join == False: \n",
    "                delta = delta * self.betta \n",
    "                continue\n",
    "            \n",
    "            M =   M_ \n",
    "                    \n",
    "            if len(M[M > min_delta]) == 0:\n",
    "                if(self.debug): \n",
    "                    print('len(M[M > min_delta]) == 0') \n",
    "                break\n",
    "               \n",
    "            y_ = np.zeros(size)\n",
    "            cl = 0\n",
    "            for c in C:\n",
    "                if(c.active() == True): \n",
    "                    for i in c.nodes:\n",
    "                        y_[i] = cl\n",
    "                    cl = cl + 1\n",
    "                    \n",
    "            self._c_all.append(y_)  \n",
    "          \n",
    "            if len(np.unique(y_)) <= self.n_clusters: \n",
    "                if(self.debug): \n",
    "                    print('len(np.unique(y_)) <= self.n_clusters') \n",
    "                break\n",
    "            # func    \n",
    "            neg,pos = [],[]    \n",
    "            for i in range(size): \n",
    "                for j in range(i,size):\n",
    "                    #if C[i].active() == False:\n",
    "                    #    continue\n",
    "                    #if C[j].active() == False:\n",
    "                    #    continue\n",
    "                        \n",
    "                    if(M[i][j] <= 0):\n",
    "                        neg.append(np.abs(M[i][j]) + delta)\n",
    "                    elif(M[i][j] > 0):\n",
    "                        pos.append(M[i][j])    \n",
    "            if(self.debug):\n",
    "                print('Sum pos: %.3f, sum neg: %.3f,Sum pos2: %.3f, sum neg2: %.3f, Std pos: %.3f, Std neg: %.3f, n_cls: %d' % \n",
    "                      (sum(pos) , sum(neg),sum(pos)/len(pos) , sum(neg)/len(neg),np.std(pos), np.std(neg), len(np.unique(y_)))) \n",
    "            if np.std(pos) == 0:\n",
    "                break\n",
    "            if self.stop_neg_sum and sum(pos) < sum(neg): \n",
    "                print('sum(pos) < sum(neg)')\n",
    "                break \n",
    "        self.labels_ = y_         \n",
    "        return y_                \n",
    "        \n",
    "    def print_name(self):\n",
    "        print('Hierarchical clustering')\n",
    "        \n",
    "    \n",
    "# ---\n",
    "class HC:\n",
    "    \n",
    "    def __init__(self, alpha = 1.01, max_iteration = 200, debug= False, delta=0., stop_neg_sum = True, betta = 2.,n_clusters=1):\n",
    "        ''' '''\n",
    "        self.alpha = alpha\n",
    "        self.betta = betta\n",
    "        self.max_iteration = max_iteration\n",
    "        self.debug = debug\n",
    "        self._c_all = []\n",
    "        self.delta = delta\n",
    "        self.stop_neg_sum = stop_neg_sum\n",
    "        self.n_clusters= n_clusters\n",
    "        self.labels_ = []\n",
    "    \n",
    "    def log(self, msg):\n",
    "        if(self.debug):\n",
    "            print(msg)\n",
    "            \n",
    "    def print_name(self):\n",
    "        self.log('HC')\n",
    "    \n",
    "    def fit(self, x): \n",
    "        ''' '''\n",
    "        A = euclidean_distances(x,x)\n",
    "        #print(A)\n",
    "        self._c_all = []\n",
    "        C = A.copy()\n",
    "        labels = [n +1 for n in range(0,len(x))]\n",
    "        #print(labels)\n",
    "        n = 1 \n",
    "        mim_1 = 0\n",
    "        for i in range(self.max_iteration):\n",
    "            if len(A[A>0]) == 0:\n",
    "                break\n",
    "            mim_ = min(A[A>0]) * self.alpha\n",
    "            if mim_ > mim_1:\n",
    "                mim_1 = mim_\n",
    "            mim_1   = mim_   \n",
    "            \n",
    "            #A = A - mim_1  \n",
    "            A[(A - mim_1 <= 0) & (C > 0)] = -n\n",
    "            C = C - mim_1\n",
    "            w1,w2 = np.where(A == -n) \n",
    "            #print(A)\n",
    "            lab= len(np.unique(labels))\n",
    "            for j in range(0, len(w1)):\n",
    "                #print((w1[j],w2[j])) !!!\n",
    "                labels[w1[j]] = labels[w2[j]]\n",
    "                #A[w2[j],:]=0\n",
    "                #A[:,w1[j]]=0\n",
    "            #print(labels)\n",
    "            if len(np.unique(labels)) == lab:\n",
    "                continue\n",
    "            self._c_all.append(labels.copy())\n",
    "            if(len(np.unique(labels)) <= self.n_clusters):\n",
    "                break\n",
    "            self.log('min: %.10f, len: %d' % (mim_1, len(np.unique(labels))))     \n",
    "            #if sum(C[C > 0]) < sum(C[C < 0] * -1):\n",
    "            #    self.log(\"By D\")\n",
    "            #    print(\"By D\")\n",
    "            #    break\n",
    "            n = n + 1\n",
    "        #print(labels)\n",
    "        #print(C)\n",
    "        self.labels_ = labels\n",
    "        return labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.0000000088, len: 5788\n",
      "min: 0.0109430680, len: 5765\n",
      "min: 0.0525544133, len: 5629\n",
      "min: 0.2473783173, len: 250\n",
      "Homogeneity: 0.232\n",
      "Completeness: 0.210\n",
      "V-measure: 0.220\n",
      "Adjusted Rand Index: 0.013\n",
      "Adjusted Mutual Information: 0.165\n",
      "Silhouette Coefficient: -0.111\n",
      "labels num: 250.000\n"
     ]
    }
   ],
   "source": [
    "m5 = HC(alpha=4.7,n_clusters=1,debug=True, stop_neg_sum=True)\n",
    "r = test_cluster(X_, Y_, m5)\n",
    "results.append(r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0,2,3], [0,0,4], [0,0,0]])\n",
    "x = np.array([[1,1], [2,2,], [3,3],[1,4]])\n",
    "A = X_ #euclidean_distances(x,x)\n",
    "#print(A)\n",
    "C = A.copy()\n",
    "n = 1\n",
    "alpha = 1.05\n",
    "mim_1 = 0\n",
    "while(True):\n",
    "    if len(A[A>0]) == 0:\n",
    "        break\n",
    "    mim_ = min(A[A>0]) * alpha\n",
    "    if mim_ > mim_1:\n",
    "        mim_1 = mim_\n",
    "  \n",
    "    print('%.10f %d' % (mim_, len(A[A>0])))\n",
    "    A = A - mim_1              \n",
    "    A[A <= 0] = 0 \n",
    "    C[(A == 0) & (C > 0)] = -n\n",
    "    n = n + 1\n",
    "\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, SparsePCA, NMF\n",
    "\n",
    "p = PCA(n_components=2)\n",
    "x1 = p.fit_transform(X_)\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.scatter(x1[:,0], x1[:,1], c=m5._c_all[-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/dftime_cat.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(m5._c_all[-4])\n",
    "u = np.unique(r)\n",
    "\n",
    "for i in u:\n",
    "    indexs = np.where(r == i)[0]\n",
    "    print('Cluster: %d, len: %d' % (i, len(indexs)))\n",
    "    for n in indexs[0:3]:\n",
    "        t,d = df.iloc[n]['title'],  df.iloc[n]['text2']\n",
    "        print('N: %d, title: %s' % (n, t))\n",
    "    print()    \n",
    "        \n",
    "        #print(df['title'][n])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Таблица результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(results, columns=[ \n",
    "    'Homogeneity', \n",
    "    'Completeness', \n",
    "    'V-measure', \n",
    "    'Adjusted Rand Index', 'Adjusted Mutual Information', 'Silhouette Coefficient', 'len'])\n",
    "df2.head(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "#from scipy.stats import \n",
    "\n",
    "?scipy.stats.t.ppf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(df2.values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест 2\n",
    "\n",
    "Сравним 4 алгоритма на синтетических наборах данных\n",
    "\n",
    "- HierarchicalClustering и DBSCAN как адаптивные алгоритмы\n",
    "\n",
    "- HierarchicalClustering и AgglomerativeClustering как аглоритмически близкие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn  import datasets\n",
    " \n",
    "#dx, dy    \n",
    "def test_2algo(func_ds, test_alg):\n",
    "    result1,result2 = [],[] \n",
    "\n",
    "    for n in range(100): \n",
    "        bx,by = func_ds()\n",
    "        n_clusters = len(np.unique(by))\n",
    "        print(n_clusters)\n",
    "        \n",
    "        m5 = HierarchicalClustering(alpha=1,n_clusters=n_clusters,debug=0)\n",
    "        r = test_cluster(bx, by, m5)\n",
    "        result1.append(r) \n",
    "\n",
    "        m3 = test_alg #DBSCAN(min_samples = 2) #DBSCAN(eps=0.103, min_samples = 2)\n",
    "        r = test_cluster(bx, by, m3)\n",
    "        result2.append(r)\n",
    "\n",
    "    df2_1 = pd.DataFrame(result1, columns=[ \n",
    "    'Homogeneity', \n",
    "    'Completeness', \n",
    "    'V-measure', \n",
    "    'Adjusted Rand Index', 'Adjusted Mutual Information', 'Silhouette Coefficient', 'len'])\n",
    "    df2_2 = pd.DataFrame(result2, columns=[ \n",
    "    'Homogeneity', \n",
    "    'Completeness', \n",
    "    'V-measure', \n",
    "    'Adjusted Rand Index', 'Adjusted Mutual Information', 'Silhouette Coefficient', 'len'])\n",
    "    \n",
    "    ###\n",
    "    # 200 - 2 = 198 => 180-199\t1.973 # http://medstatistic.ru/theory/t_cryteria.html\n",
    "    # http://medstatistic.ru/theory/t_cryteria.html\n",
    "    ss = 1.973\n",
    "    df2_1.replace([np.inf, -np.inf], np.nan)\n",
    "    df2_2.replace([np.inf, -np.inf], np.nan)\n",
    "    df2_1.fillna(0)\n",
    "    df2_2.fillna(0)\n",
    "    for c in df2_1.columns:\n",
    "        \n",
    "        # print(df2_1[c].values)\n",
    "        # print(df2_2[c].values)\n",
    "        tStat = ttest_ind(df2_1[c].values, df2_2[c].values)\n",
    "        z = \"<\"\n",
    "        if df2_1[c].mean() > df2_2[c].mean():\n",
    "            z = \">\"\n",
    "        print('%s: important: %s, alg1: %.4f, alg2: %.4f %s %.4f' % (c, np.abs(tStat.statistic) > ss, tStat.statistic, df2_1[c].mean(), z, df2_2[c].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "?datasets.make_circles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2 класса\n",
    "\n",
    "- make_blobs\n",
    "- moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN VS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def ds2():\n",
    "    return datasets.make_blobs(n_samples=100,  n_features=3, cluster_std=1 + np.random.rand())\n",
    " \n",
    "def ds2moon():\n",
    "    return datasets.make_moons(n_samples=100,   noise=.05)\n",
    "\n",
    "# dep\n",
    "def ds2b2():\n",
    "    return datasets.make_blobs(n_samples=100,cluster_std=[1.0, 2.5, 0.5],random_state=60)\n",
    "\n",
    "def ds2circl():\n",
    "    return datasets.make_circles(n_samples=100, factor=.5, noise=.05, random_state=np.random.randint(1,255))\n",
    "\n",
    "def ds2len(): \n",
    "    X, y = datasets.make_blobs(n_samples=100, random_state=np.random.randint(1,255))\n",
    "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "    x = np.dot(X, transformation)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "test_2algo(ds2, DBSCAN(eps=0.212, min_samples = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds2moon, DBSCAN(eps=0.212, min_samples = 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_2algo(ds2b2, DBSCAN(eps=0.212, min_samples = 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds2circl, DBSCAN(eps=0.212, min_samples = 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds2len, DBSCAN(eps=0.212, min_samples = 2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vs AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yy = ds2()\n",
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_2algo(ds2, AgglomerativeClustering(n_clusters = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yy = ds2moon()\n",
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds2moon, AgglomerativeClustering(n_clusters = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yy = ds2b2()\n",
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_2algo(ds2b2, AgglomerativeClustering(n_clusters = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yy = ds2circl()\n",
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds2circl, AgglomerativeClustering(n_clusters = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,yy = ds2len()\n",
    "np.unique(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds2circl, AgglomerativeClustering(n_clusters = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 класса\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds10():\n",
    "    return datasets.make_classification(n_classes=10, n_informative=10)\n",
    "\n",
    "test_2algo(ds10, DBSCAN(eps=0.212, min_samples = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2algo(ds10, AgglomerativeClustering(n_clusters = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
