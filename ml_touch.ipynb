{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Touch\n",
    "\n",
    "Имеем два набора данных. один набор размечен пользователями 28 примеров, второй набор размечан автоматически 3188.\n",
    "\n",
    "Проверим, насколько автоматически полученные данные, хорошо описывают размеченные вручную.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pn\n",
    "import numpy as np\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: 15\n"
     ]
    }
   ],
   "source": [
    "file_name_user = 'data_sets/mphone_mark_users.csv'\n",
    "file_name_auto = 'data_sets/mphone_mark_auto.csv'\n",
    "\n",
    "#?pn.read_csv\n",
    "columns = [\"Gender\",\"Fingerprint\",\"TimeUpx\",\"W\",\"H\",\"leng\",\"leng_sum\",\"speed\",\"Force\",\"ForceUp\",\"Rx\",\"Ry\",\"varX\",\"varY\",\"coorXY\"]\n",
    "print('columns: %d' % len(columns))\n",
    "df_user = pn.read_csv(file_name_user, nrows=15000, names=columns, header=1)\n",
    "df_auto = pn.read_csv(file_name_auto, nrows=15000, names=columns, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeUpx</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>leng</th>\n",
       "      <th>leng_sum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Force</th>\n",
       "      <th>ForceUp</th>\n",
       "      <th>Rx</th>\n",
       "      <th>Ry</th>\n",
       "      <th>varX</th>\n",
       "      <th>varY</th>\n",
       "      <th>coorXY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>373.723473</td>\n",
       "      <td>350.370370</td>\n",
       "      <td>662.592593</td>\n",
       "      <td>177.994823</td>\n",
       "      <td>1216.167096</td>\n",
       "      <td>0.483212</td>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>12.715362</td>\n",
       "      <td>12.715362</td>\n",
       "      <td>2086.672672</td>\n",
       "      <td>1.793523e+05</td>\n",
       "      <td>-0.146530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>302.411272</td>\n",
       "      <td>20.751549</td>\n",
       "      <td>75.541257</td>\n",
       "      <td>296.190706</td>\n",
       "      <td>1043.608911</td>\n",
       "      <td>0.349451</td>\n",
       "      <td>0.499913</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>15.919060</td>\n",
       "      <td>15.919060</td>\n",
       "      <td>3643.059642</td>\n",
       "      <td>4.694765e+05</td>\n",
       "      <td>0.720704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>24.745730</td>\n",
       "      <td>77.820310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.715000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>50.585805</td>\n",
       "      <td>386.837215</td>\n",
       "      <td>0.193145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.070085</td>\n",
       "      <td>7.912361e+02</td>\n",
       "      <td>-0.830993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>295.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>108.321700</td>\n",
       "      <td>720.271370</td>\n",
       "      <td>0.434170</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>538.249140</td>\n",
       "      <td>4.420800e+03</td>\n",
       "      <td>-0.164595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>454.083335</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>147.380345</td>\n",
       "      <td>2233.540275</td>\n",
       "      <td>0.757295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.601315</td>\n",
       "      <td>28.601315</td>\n",
       "      <td>2109.694450</td>\n",
       "      <td>1.430145e+05</td>\n",
       "      <td>0.562660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1385.666670</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>1591.342210</td>\n",
       "      <td>3439.153620</td>\n",
       "      <td>1.155530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031670</td>\n",
       "      <td>44.886670</td>\n",
       "      <td>44.886670</td>\n",
       "      <td>14559.183400</td>\n",
       "      <td>2.301841e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TimeUpx           W           H         leng     leng_sum  \\\n",
       "count    27.000000   27.000000   27.000000    27.000000    27.000000   \n",
       "mean    373.723473  350.370370  662.592593   177.994823  1216.167096   \n",
       "std     302.411272   20.751549   75.541257   296.190706  1043.608911   \n",
       "min       0.000000  320.000000  568.000000    24.745730    77.820310   \n",
       "25%     184.715000  320.000000  568.000000    50.585805   386.837215   \n",
       "50%     295.000000  360.000000  667.000000   108.321700   720.271370   \n",
       "75%     454.083335  360.000000  740.000000   147.380345  2233.540275   \n",
       "max    1385.666670  375.000000  760.000000  1591.342210  3439.153620   \n",
       "\n",
       "           speed      Force    ForceUp         Rx         Ry          varX  \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000     27.000000   \n",
       "mean    0.483212   0.452393   0.002481  12.715362  12.715362   2086.672672   \n",
       "std     0.349451   0.499913   0.007526  15.919060  15.919060   3643.059642   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000      0.000000   \n",
       "25%     0.193145   0.000000   0.000000   0.000000   0.000000    113.070085   \n",
       "50%     0.434170   0.056330   0.000000   0.659180   0.659180    538.249140   \n",
       "75%     0.757295   1.000000   0.000000  28.601315  28.601315   2109.694450   \n",
       "max     1.155530   1.000000   0.031670  44.886670  44.886670  14559.183400   \n",
       "\n",
       "               varY     coorXY  \n",
       "count  2.700000e+01  24.000000  \n",
       "mean   1.793523e+05  -0.146530  \n",
       "std    4.694765e+05   0.720704  \n",
       "min    0.000000e+00  -1.000000  \n",
       "25%    7.912361e+02  -0.830993  \n",
       "50%    4.420800e+03  -0.164595  \n",
       "75%    1.430145e+05   0.562660  \n",
       "max    2.301841e+06   1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "f    798.318759\n",
       "m    638.121060\n",
       "Name: TimeUpx, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.groupby('Gender')['TimeUpx'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "f    148.007995\n",
       "m    132.999248\n",
       "Name: leng, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.groupby('Gender')['leng'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "f    0.874330\n",
       "m    0.752413\n",
       "Name: Force, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.groupby('Gender')['Force'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rx</th>\n",
       "      <th>Ry</th>\n",
       "      <th>coorXY</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>2.567778</td>\n",
       "      <td>2.602028</td>\n",
       "      <td>-0.066153</td>\n",
       "      <td>377.729393</td>\n",
       "      <td>646.302433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1.554696</td>\n",
       "      <td>1.590240</td>\n",
       "      <td>-0.069216</td>\n",
       "      <td>366.947321</td>\n",
       "      <td>637.688832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rx        Ry    coorXY           W           H\n",
       "Gender                                                      \n",
       "f       2.567778  2.602028 -0.066153  377.729393  646.302433\n",
       "m       1.554696  1.590240 -0.069216  366.947321  637.688832"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.groupby('Gender')[['Rx', 'Ry', 'coorXY','W','H']].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "f    0.363421\n",
       "m    0.383270\n",
       "Name: speed, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.groupby('Gender')['speed'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varX</th>\n",
       "      <th>varY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>2035.499450</td>\n",
       "      <td>3616.160606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1805.778574</td>\n",
       "      <td>3208.915972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               varX         varY\n",
       "Gender                          \n",
       "f       2035.499450  3616.160606\n",
       "m       1805.778574  3208.915972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.groupby('Gender')[['varX','varY']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeUpx</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>leng</th>\n",
       "      <th>leng_sum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Force</th>\n",
       "      <th>ForceUp</th>\n",
       "      <th>Rx</th>\n",
       "      <th>Ry</th>\n",
       "      <th>varX</th>\n",
       "      <th>varY</th>\n",
       "      <th>coorXY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10644.000000</td>\n",
       "      <td>10279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>707.804952</td>\n",
       "      <td>371.637381</td>\n",
       "      <td>641.435635</td>\n",
       "      <td>139.527856</td>\n",
       "      <td>2694.803250</td>\n",
       "      <td>0.374636</td>\n",
       "      <td>0.805445</td>\n",
       "      <td>0.068238</td>\n",
       "      <td>1.995374</td>\n",
       "      <td>2.030354</td>\n",
       "      <td>1905.704134</td>\n",
       "      <td>3386.062032</td>\n",
       "      <td>-0.067904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1020.106998</td>\n",
       "      <td>82.716043</td>\n",
       "      <td>70.244010</td>\n",
       "      <td>78.123945</td>\n",
       "      <td>4787.211611</td>\n",
       "      <td>0.268494</td>\n",
       "      <td>0.364696</td>\n",
       "      <td>0.247177</td>\n",
       "      <td>3.082946</td>\n",
       "      <td>3.071559</td>\n",
       "      <td>5792.952804</td>\n",
       "      <td>4655.824619</td>\n",
       "      <td>0.545733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>241.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>83.894675</td>\n",
       "      <td>883.082582</td>\n",
       "      <td>0.223275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.963543</td>\n",
       "      <td>564.379192</td>\n",
       "      <td>-0.512135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>429.530920</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>119.652210</td>\n",
       "      <td>1658.038115</td>\n",
       "      <td>0.332900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>355.246530</td>\n",
       "      <td>1725.777780</td>\n",
       "      <td>-0.092650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>805.145840</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>173.734630</td>\n",
       "      <td>2996.418408</td>\n",
       "      <td>0.467540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.913510</td>\n",
       "      <td>2.915433</td>\n",
       "      <td>1258.786462</td>\n",
       "      <td>4351.189798</td>\n",
       "      <td>0.346570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32463.000000</td>\n",
       "      <td>1280.000000</td>\n",
       "      <td>1280.000000</td>\n",
       "      <td>584.874850</td>\n",
       "      <td>193153.414370</td>\n",
       "      <td>10.135830</td>\n",
       "      <td>1.587500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.333340</td>\n",
       "      <td>42.333340</td>\n",
       "      <td>200741.280280</td>\n",
       "      <td>83784.223260</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TimeUpx             W             H          leng       leng_sum  \\\n",
       "count  10644.000000  10644.000000  10644.000000  10644.000000   10644.000000   \n",
       "mean     707.804952    371.637381    641.435635    139.527856    2694.803250   \n",
       "std     1020.106998     82.716043     70.244010     78.123945    4787.211611   \n",
       "min        0.000000    320.000000    320.000000      0.000000       0.000000   \n",
       "25%      241.000000    360.000000    640.000000     83.894675     883.082582   \n",
       "50%      429.530920    360.000000    640.000000    119.652210    1658.038115   \n",
       "75%      805.145840    360.000000    640.000000    173.734630    2996.418408   \n",
       "max    32463.000000   1280.000000   1280.000000    584.874850  193153.414370   \n",
       "\n",
       "              speed         Force       ForceUp            Rx            Ry  \\\n",
       "count  10644.000000  10644.000000  10644.000000  10644.000000  10644.000000   \n",
       "mean       0.374636      0.805445      0.068238      1.995374      2.030354   \n",
       "std        0.268494      0.364696      0.247177      3.082946      3.071559   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.223275      1.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.332900      1.000000      0.000000      0.687500      0.750000   \n",
       "75%        0.467540      1.000000      0.000000      2.913510      2.915433   \n",
       "max       10.135830      1.587500      1.000000     42.333340     42.333340   \n",
       "\n",
       "                varX          varY        coorXY  \n",
       "count   10644.000000  10644.000000  10279.000000  \n",
       "mean     1905.704134   3386.062032     -0.067904  \n",
       "std      5792.952804   4655.824619      0.545733  \n",
       "min         0.000000      0.000000     -1.000000  \n",
       "25%       115.963543    564.379192     -0.512135  \n",
       "50%       355.246530   1725.777780     -0.092650  \n",
       "75%      1258.786462   4351.189798      0.346570  \n",
       "max    200741.280280  83784.223260      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeUpx</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>leng</th>\n",
       "      <th>leng_sum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Force</th>\n",
       "      <th>ForceUp</th>\n",
       "      <th>Rx</th>\n",
       "      <th>Ry</th>\n",
       "      <th>varX</th>\n",
       "      <th>varY</th>\n",
       "      <th>coorXY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4630</td>\n",
       "      <td>4402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>6014</td>\n",
       "      <td>5877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TimeUpx     W     H  leng  leng_sum  speed  Force  ForceUp    Rx  \\\n",
       "Gender                                                                     \n",
       "f          4630  4630  4630  4630      4630   4630   4630     4630  4630   \n",
       "m          6014  6014  6014  6014      6014   6014   6014     6014  6014   \n",
       "\n",
       "          Ry  varX  varY  coorXY  \n",
       "Gender                            \n",
       "f       4630  4630  4630    4402  \n",
       "m       6014  6014  6014    5877  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.set_index([\"Gender\",\"Fingerprint\"]).count(level=\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df_user = df_user.fillna(0)\n",
    "df_auto = df_auto.fillna(0)\n",
    "\n",
    "def map_target(cl):\n",
    "    if(cl == 'f'):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "X = df_auto[columns[2:]]\n",
    "X_test =df_user[columns[2:]]\n",
    "Y = df_auto['Gender'].map(map_target)\n",
    "Y_test = df_user['Gender'].map(map_target) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3254224c90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f32498de710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEn1JREFUeJzt3X+sX3d93/Hnq3bpNN9gaDNuQ5LOmZZGC8lIyVUAreruXWhmXES2jnWx1oHbbLdlpdqPaJu3SlAVTaKqQtUS1OAWyzDRXLppGRYOpBHjzmUiFLtNsKFQ0uAW32TxglOvF9J1hvf+uF9Lt7f35n5zztffb64/z4d0dc+Pzzmfz9v3+nXP/XzP99xUFZKkdnzbpAcgSRovg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmO2THsB6Lr/88tq1a1enY7/+9a+zY8eO0Q7oBc6aL32t1QvW/HwdP3786ar6K8O0fUEG/65duzh27FinYxcXF5mdnR3tgF7grPnS11q9YM3PV5I/HLatUz2S1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSYF+Q7dyVpknbtPzKRfg/tHs8jKrzil6TGbHrFn+Qg8AbgTFXdMNj2YeC6QZOXAH9cVTetc+wp4E+AbwLnq2pmROOWJHU0zFTPIeAe4IMXNlTVP7qwnORu4NxzHD9XVU93HaAkabQ2Df6qOppk13r7kgT4EeDvjHZYkqSLJVW1eaOV4P/ohameVdt/AHj3RlM4Sb4CPAMU8L6qOvAcfcwD8wDT09M3LywsDFnCn7e8vMzU1FSnY7cqa770tVYvTLbmE0vPNYlx8Vyzc1vnmufm5o4PO53e966evcB9z7H/+6tqKcnLgIeSfLGqjq7XcPBD4QDAzMxMdX0mtc/wbkNrNbdWL0y25n0TvKtnHDV3vqsnyXbgh4EPb9SmqpYGn88A9wO3dO1PkjQafW7nfB3wxao6vd7OJDuSXHZhGbgNONmjP0nSCGwa/EnuAz4NXJfkdJI7B7vuYM00T5KXJ3lgsDoNfCrJo8BvA0eq6uOjG7okqYth7urZu8H2fetsewLYM1h+HHhlz/FJkkbMd+5KUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxmwZ/koNJziQ5uWrbzyZZSvLI4GPPBsfuTvKlJI8l2T/KgUuSuhnmiv8QsHud7b9YVTcNPh5YuzPJNuC9wOuB64G9Sa7vM1hJUn+bBn9VHQXOdjj3LcBjVfV4Vf0ZsADc3uE8kqQR2t7j2LcleTNwDLirqp5Zs/9K4Kur1k8Dr97oZEnmgXmA6elpFhcXOw1qeXm587FblTVf+lqrFyZb8103np9Iv+OquWvw/wrwTqAGn+8GfrzPQKrqAHAAYGZmpmZnZzudZ3Fxka7HblXWfOlrrV6YbM379h+ZSL+Hdu8YS82d7uqpqqeq6ptV9S3gV1mZ1llrCbh61fpVg22SpAnqFPxJrli1+veBk+s0+yxwbZJrkrwIuAM43KU/SdLobDrVk+Q+YBa4PMlp4B3AbJKbWJnqOQX8xKDty4Ffq6o9VXU+yduAB4FtwMGq+vxFqUKSNLRNg7+q9q6z+f0btH0C2LNq/QHgL9zqKUmaHN+5K0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVm0+BPcjDJmSQnV237hSRfTPK5JPcneckGx55KciLJI0mOjXLgkqRuhrniPwTsXrPtIeCGqvqbwO8D//45jp+rqpuqaqbbECVJo7Rp8FfVUeDsmm2/WVXnB6sPA1ddhLFJki6CUczx/zjwsQ32FfCbSY4nmR9BX5KknlJVmzdKdgEfraob1mz/GWAG+OFa50RJrqyqpSQvY2V66KcHv0Gs18c8MA8wPT1988LCwvMsZcXy8jJTU1Odjt2qrPnS11q9MNmaTyydm0i/1+zc1rnmubm548NOqW/v1AOQZB/wBuDW9UIfoKqWBp/PJLkfuAVYN/ir6gBwAGBmZqZmZ2c7jWtxcZGux25V1nzpa61emGzN+/YfmUi/h3bvGEvNnaZ6kuwG/i3wxqr6xgZtdiS57MIycBtwcr22kqTxGeZ2zvuATwPXJTmd5E7gHuAy4KHBrZr3Dtq+PMkDg0OngU8leRT4beBIVX38olQhSRraplM9VbV3nc3v36DtE8CewfLjwCt7jU6SNHK+c1eSGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0ZKviTHExyJsnJVdu+M8lDSb48+PzSDY59y6DNl5O8ZVQDlyR1M+wV/yFg95pt+4FPVNW1wCcG639Oku8E3gG8GrgFeMdGPyAkSeMxVPBX1VHg7JrNtwMfGCx/APh76xz6d4GHqupsVT0DPMRf/AEiSRqjPnP801X15GD5fwHT67S5EvjqqvXTg22SpAnZPoqTVFUlqT7nSDIPzANMT0+zuLjY6TzLy8udj92qrPnS11q9MNma77rx/ET6HVfNfYL/qSRXVNWTSa4AzqzTZgmYXbV+FbC43smq6gBwAGBmZqZmZ2fXa7apxcVFuh67VVnzpa+1emGyNe/bf2Qi/R7avWMsNfeZ6jkMXLhL5y3AR9Zp8yBwW5KXDl7UvW2wTZI0IcPeznkf8GnguiSnk9wJvAv4wSRfBl43WCfJTJJfA6iqs8A7gc8OPn5usE2SNCFDTfVU1d4Ndt26TttjwD9dtX4QONhpdJKkkfOdu5LUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxI3lkwwvJiaVzE3nX3al3/dDY+5SkLrzil6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5Jakzn4E9yXZJHVn38nyT/ck2b2STnVrV5e/8hS5L66PxY5qr6EnATQJJtwBJw/zpNf6uq3tC1H0nSaI1qqudW4A+q6g9HdD5J0kUyquC/A7hvg32vTfJoko8lecWI+pMkdZSq6neC5EXAE8ArquqpNfteDHyrqpaT7AF+qaqu3eA888A8wPT09M0LCwudxnPm7DmeerbTob3ceOXO8Xc6sLy8zNTU1MT6n4TWam6tXphszSeWzk2k32t2butc89zc3PGqmhmm7SiC/3bgp6rqtiHangJmqurp52o3MzNTx44d6zSe93zoI9x9Yvx/UXKSf3pxcXGR2dnZifU/Ca3V3Fq9MNmad03gz7cCHNq9o3PNSYYO/lFM9exlg2meJN+dJIPlWwb9fW0EfUqSOup1aZxkB/CDwE+s2vaTAFV1L/Am4K1JzgPPAndU318xJEm99Ar+qvo68F1rtt27avke4J4+fUiSRst37kpSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTG9gz/JqSQnkjyS5Ng6+5Pkl5M8luRzSV7Vt09JUnfbR3Seuap6eoN9rweuHXy8GviVwWdJ0gSMY6rnduCDteJh4CVJrhhDv5KkdaSq+p0g+QrwDFDA+6rqwJr9HwXeVVWfGqx/Avh3VXVsTbt5YB5genr65oWFhU7jOXP2HE892+nQXm68cuf4Ox1YXl5mampqYv1PQms1t1YvTLbmE0vnJtLvNTu3da55bm7ueFXNDNN2FFM9319VS0leBjyU5ItVdfT5nmTwA+MAwMzMTM3OznYazHs+9BHuPjGqGazhnfrHs2Pv84LFxUW6/nttVa3V3Fq9MNma9+0/MpF+D+3eMZaae0/1VNXS4PMZ4H7gljVNloCrV61fNdgmSZqAXsGfZEeSyy4sA7cBJ9c0Owy8eXB3z2uAc1X1ZJ9+JUnd9Z0TmQbuT3LhXL9eVR9P8pMAVXUv8ACwB3gM+AbwYz37lCT10Cv4q+px4JXrbL931XIBP9WnH0nS6PjOXUlqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxnYM/ydVJPpnkC0k+n+RfrNNmNsm5JI8MPt7eb7iSpL76/LH188BdVfU7SS4Djid5qKq+sKbdb1XVG3r0I0kaoc5X/FX1ZFX9zmD5T4DfA64c1cAkSRfHSOb4k+wCvg/4zDq7X5vk0SQfS/KKUfQnSeouVdXvBMkU8D+A/1hV/3XNvhcD36qq5SR7gF+qqms3OM88MA8wPT1988LCQqfxnDl7jqee7XRoLzdeuXP8nQ4sLy8zNTU1sf4nobWaW6sXJlvziaVzE+n3mp3bOtc8Nzd3vKpmhmnbK/iTfDvwUeDBqnr3EO1PATNV9fRztZuZmaljx451GtN7PvQR7j7R56WLbk6964fG3ucFi4uLzM7OTqz/SWit5tbqhcnWvGv/kYn0e2j3js41Jxk6+Pvc1RPg/cDvbRT6Sb570I4ktwz6+1rXPiVJ/fW5NP5bwD8BTiR5ZLDtPwDfA1BV9wJvAt6a5DzwLHBH9Z1bkiT10jn4q+pTQDZpcw9wT9c+JEmj5zt3JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmF7Bn2R3ki8leSzJ/nX2f0eSDw/2fybJrj79SZL66xz8SbYB7wVeD1wP7E1y/ZpmdwLPVNVfB34R+Pmu/UmSRqPPFf8twGNV9XhV/RmwANy+ps3twAcGy/8FuDVJevQpSeqpT/BfCXx11frpwbZ121TVeeAc8F09+pQk9bR90gO4IMk8MD9YXU7ypY6nuhx4ejSjGl4mO4k1kZonrLWaW6sXGqx57ud71fxXh23YJ/iXgKtXrV812LZem9NJtgM7ga+td7KqOgAc6DEeAJIcq6qZvufZSqz50tdavWDNF1OfqZ7PAtcmuSbJi4A7gMNr2hwG3jJYfhPw36uqevQpSeqp8xV/VZ1P8jbgQWAbcLCqPp/k54BjVXUYeD/wn5I8Bpxl5YeDJGmCes3xV9UDwANrtr191fKfAv+wTx8d9J4u2oKs+dLXWr1gzRdNnHmRpLb4yAZJasyWDf7WHhcxRL3/OskXknwuySeSDH1r1wvVZjWvavcPklSSLX8HyDA1J/mRwdf680l+fdxjHLUhvre/J8knk/zu4Pt7zyTGOSpJDiY5k+TkBvuT5JcH/x6fS/KqkQ+iqrbcBysvJv8B8NeAFwGPAtevafPPgXsHy3cAH570uC9yvXPAXx4sv3Ur1ztszYN2lwFHgYeBmUmPewxf52uB3wVeOlh/2aTHPYaaDwBvHSxfD5ya9Lh71vwDwKuAkxvs3wN8DAjwGuAzox7DVr3ib+1xEZvWW1WfrKpvDFYfZuV9FVvZMF9jgHey8gyoPx3n4C6SYWr+Z8B7q+oZgKo6M+YxjtowNRfw4sHyTuCJMY5v5KrqKCt3OW7kduCDteJh4CVJrhjlGLZq8Lf2uIhh6l3tTlauGLayTWse/Ap8dVUdGefALqJhvs7fC3xvkv+Z5OEku8c2uotjmJp/FvjRJKdZuYvwp8cztIl5vv/fn7cXzCMbNBpJfhSYAf72pMdyMSX5NuDdwL4JD2XctrMy3TPLym91R5PcWFV/PNFRXVx7gUNVdXeS17Ly3qAbqupbkx7YVrVVr/ifz+Mi2OxxEVvAMPWS5HXAzwBvrKr/O6axXSyb1XwZcAOwmOQUK3Ohh7f4C7zDfJ1PA4er6v9V1VeA32flB8FWNUzNdwK/AVBVnwb+EivP8blUDfX/vY+tGvytPS5i03qTfB/wPlZCf6vP+8ImNVfVuaq6vKp2VdUuVl7XeGNVHZvMcEdimO/r/8bK1T5JLmdl6ufxcQ5yxIap+Y+AWwGS/A1Wgv9/j3WU43UYePPg7p7XAOeq6slRdrAlp3qqscdFDFnvLwBTwH8evIb9R1X1xokNuqcha76kDFnzg8BtSb4AfBP4N1W1VX+THbbmu4BfTfKvWHmhd98WvogjyX2s/PC+fPC6xTuAbweoqntZeR1jD/AY8A3gx0Y+hi387ydJ6mCrTvVIkjoy+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5Jasz/B/oqDuZPhGj2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_test.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(clf, columns_x, max_top = 10):\n",
    "    results = []\n",
    "    for i in range(0,len(clf.feature_importances_)):\n",
    "        m = clf.feature_importances_[i]\n",
    "        results.append((m, i)) \n",
    "        \n",
    "    results.sort(key=lambda x: x[0], reverse=True)  \n",
    "    max_top = min(max_top, len(columns_x)-1)\n",
    "    for i in range(0, max_top):\n",
    "        r = results[i]\n",
    "        print('Key: %12s: %.4f' % (columns_x[r[1]], r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20, max_depth=4, random_state=0)\n",
    "clf.fit(X_std,Y)\n",
    "print(clf.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "Key:        Force: 0.3009\n",
      "Key:           Ry: 0.1560\n",
      "Key:            H: 0.1468\n",
      "Key:           Rx: 0.1455\n",
      "Key:      ForceUp: 0.1229\n",
      "Key:            W: 0.0622\n",
      "Key:         leng: 0.0166\n",
      "Key:      TimeUpx: 0.0160\n",
      "Key:         varX: 0.0107\n",
      "Key:        speed: 0.0106\n"
     ]
    }
   ],
   "source": [
    "print(type(X_std))\n",
    "\n",
    "show_feature_importances(clf, columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.11      0.25      0.15         4\n",
      "          1       0.83      0.65      0.73        23\n",
      "\n",
      "avg / total       0.73      0.59      0.65        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(clf.predict(X_test_std), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 3, score: 0.481, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, score: 0.667, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, score: 0.704, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, score: 0.704, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 7, score: 0.704, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: -1, score: 0.667, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for md in [3,4,5,6,7,None]:\n",
    "    tree = DecisionTreeClassifier(max_depth=md,random_state=42) \n",
    "    tree.fit(X_std, Y)\n",
    " \n",
    "    sc = tree.score(X_test_std, Y_test)\n",
    "    scores = cross_val_score(tree,  X_test_std, Y_test, cv=5)\n",
    "    if(md == None):\n",
    "        md = -1\n",
    "    print(\"max_depth: %d, score: %.3f, m-score: %.3f, sc: [%s]\" % \n",
    "              (md, sc, scores.mean(), ', '.join(map(lambda t: '%.3f' % t,scores.tolist())))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:            W: 0.1414\n",
      "Key:           Ry: 0.1070\n",
      "Key:        Force: 0.0981\n",
      "Key:         leng: 0.0820\n",
      "Key:        speed: 0.0750\n",
      "Key:            H: 0.0714\n",
      "Key:      TimeUpx: 0.0688\n",
      "Key:     leng_sum: 0.0654\n",
      "Key:         varX: 0.0636\n",
      "Key:           Rx: 0.0629\n"
     ]
    }
   ],
   "source": [
    "show_feature_importances(tree, columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.50      0.47         8\n",
      "          1       0.78      0.74      0.76        19\n",
      "\n",
      "avg / total       0.68      0.67      0.67        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(tree.predict(X_test_std), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=2, n_estimators=25, random_state=42)\n",
    "clf.fit(X_std,Y)\n",
    "print(clf.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.36      0.43        14\n",
      "           1       0.50      0.69      0.58        13\n",
      "\n",
      "   micro avg       0.52      0.52      0.52        27\n",
      "   macro avg       0.53      0.52      0.51        27\n",
      "weighted avg       0.53      0.52      0.51        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(clf.predict(X_test_std), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2, n_estimators:  10, score: 0.556, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 2, n_estimators:  25, score: 0.519, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 2, n_estimators:  50, score: 0.519, m-score: 0.653, sc: [0.667, 0.667, 0.833, 0.600, 0.500]\n",
      "max_depth: 2, n_estimators: 100, score: 0.519, m-score: 0.653, sc: [0.833, 0.667, 0.667, 0.600, 0.500]\n",
      "max_depth: 2, n_estimators: 200, score: 0.667, m-score: 0.743, sc: [0.833, 0.667, 0.667, 0.800, 0.750]\n",
      "max_depth: 3, n_estimators:  10, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators:  25, score: 0.630, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators:  50, score: 0.630, m-score: 0.693, sc: [0.833, 0.667, 0.667, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators: 100, score: 0.667, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators: 200, score: 0.667, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators:  10, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators:  25, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators:  50, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators: 100, score: 0.593, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators: 200, score: 0.593, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators:  10, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators:  25, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators:  50, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators: 100, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators: 200, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators:  10, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators:  25, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators:  50, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators: 100, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators: 200, score: 0.704, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#?GradientBoostingClassifier\n",
    "for md in [2,3,4,5,6]:\n",
    "    for ne in [10,25,50,100,200]:\n",
    "        clf = GradientBoostingClassifier(max_depth=md,n_estimators=ne, random_state=42)\n",
    "        clf.fit(X_std,Y)\n",
    "        sc = clf.score(X_test_std, Y_test)\n",
    "        scores = cross_val_score(clf,  X_test_std, Y_test, cv=5)\n",
    "        print(\"max_depth: %d, n_estimators: %3d, score: %.3f, m-score: %.3f, sc: [%s]\" % \n",
    "              (md, ne, sc, scores.mean(), ', '.join(map(lambda t: '%.3f' % t,scores.tolist()))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  NN keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential() \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal', input_dim=len(X_std[0]))) \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10644 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "10644/10644 [==============================] - 3s 258us/step - loss: 0.6279 - acc: 0.6443 - val_loss: 1.3320 - val_acc: 0.5185\n",
      "Epoch 2/100\n",
      "10644/10644 [==============================] - 2s 199us/step - loss: 0.5661 - acc: 0.6847 - val_loss: 1.7928 - val_acc: 0.4444\n",
      "Epoch 3/100\n",
      "10644/10644 [==============================] - 2s 205us/step - loss: 0.5474 - acc: 0.7057 - val_loss: 2.1278 - val_acc: 0.4444\n",
      "Epoch 4/100\n",
      "10644/10644 [==============================] - 2s 205us/step - loss: 0.5316 - acc: 0.7187 - val_loss: 2.2979 - val_acc: 0.4074\n",
      "Epoch 5/100\n",
      "10644/10644 [==============================] - 2s 209us/step - loss: 0.5175 - acc: 0.7347 - val_loss: 2.4028 - val_acc: 0.5185\n",
      "Epoch 6/100\n",
      "10644/10644 [==============================] - 2s 216us/step - loss: 0.4989 - acc: 0.7518 - val_loss: 2.3947 - val_acc: 0.5185\n",
      "Epoch 7/100\n",
      "10644/10644 [==============================] - 2s 197us/step - loss: 0.4861 - acc: 0.7599 - val_loss: 2.4345 - val_acc: 0.5185\n",
      "Epoch 8/100\n",
      "10644/10644 [==============================] - 2s 212us/step - loss: 0.4758 - acc: 0.7716 - val_loss: 2.2884 - val_acc: 0.5185\n",
      "Epoch 9/100\n",
      "10644/10644 [==============================] - 2s 202us/step - loss: 0.4681 - acc: 0.7749 - val_loss: 2.4325 - val_acc: 0.5556\n",
      "Epoch 10/100\n",
      "10644/10644 [==============================] - 2s 205us/step - loss: 0.4668 - acc: 0.7747 - val_loss: 2.3973 - val_acc: 0.5185\n",
      "Epoch 11/100\n",
      "10644/10644 [==============================] - 2s 206us/step - loss: 0.4622 - acc: 0.7784 - val_loss: 2.3616 - val_acc: 0.5556\n",
      "Epoch 12/100\n",
      "10644/10644 [==============================] - 2s 212us/step - loss: 0.4577 - acc: 0.7800 - val_loss: 2.5101 - val_acc: 0.5926\n",
      "Epoch 13/100\n",
      "10644/10644 [==============================] - 2s 214us/step - loss: 0.4554 - acc: 0.7848 - val_loss: 2.5604 - val_acc: 0.5556\n",
      "Epoch 14/100\n",
      "10644/10644 [==============================] - 2s 211us/step - loss: 0.4554 - acc: 0.7766 - val_loss: 2.4864 - val_acc: 0.5926\n",
      "Epoch 15/100\n",
      "10644/10644 [==============================] - 3s 250us/step - loss: 0.4476 - acc: 0.7836 - val_loss: 2.6860 - val_acc: 0.5556\n",
      "Epoch 16/100\n",
      "10644/10644 [==============================] - 2s 221us/step - loss: 0.4469 - acc: 0.7884 - val_loss: 3.0711 - val_acc: 0.5185\n",
      "Epoch 17/100\n",
      "10644/10644 [==============================] - 2s 231us/step - loss: 0.4419 - acc: 0.7857 - val_loss: 2.6843 - val_acc: 0.5926\n",
      "Epoch 18/100\n",
      "10644/10644 [==============================] - 3s 253us/step - loss: 0.4425 - acc: 0.7882 - val_loss: 2.6800 - val_acc: 0.5556\n",
      "Epoch 19/100\n",
      "10644/10644 [==============================] - 3s 280us/step - loss: 0.4374 - acc: 0.7915 - val_loss: 3.0925 - val_acc: 0.5185\n",
      "Epoch 20/100\n",
      "10644/10644 [==============================] - 2s 206us/step - loss: 0.4334 - acc: 0.7929 - val_loss: 2.6825 - val_acc: 0.5926\n",
      "Epoch 21/100\n",
      "10644/10644 [==============================] - 2s 220us/step - loss: 0.4328 - acc: 0.7947 - val_loss: 3.0485 - val_acc: 0.5556\n",
      "Epoch 22/100\n",
      "10644/10644 [==============================] - 3s 249us/step - loss: 0.4322 - acc: 0.7947 - val_loss: 2.9287 - val_acc: 0.6667\n",
      "Epoch 23/100\n",
      "10644/10644 [==============================] - 2s 232us/step - loss: 0.4297 - acc: 0.7924 - val_loss: 2.9943 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "10644/10644 [==============================] - 2s 211us/step - loss: 0.4274 - acc: 0.7959 - val_loss: 2.8740 - val_acc: 0.5926\n",
      "Epoch 25/100\n",
      "10644/10644 [==============================] - 2s 222us/step - loss: 0.4222 - acc: 0.8003 - val_loss: 3.1110 - val_acc: 0.5926\n",
      "Epoch 26/100\n",
      "10644/10644 [==============================] - 2s 205us/step - loss: 0.4239 - acc: 0.7986 - val_loss: 3.2241 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "10644/10644 [==============================] - 2s 211us/step - loss: 0.4248 - acc: 0.7964 - val_loss: 3.3605 - val_acc: 0.5185\n",
      "Epoch 28/100\n",
      "10644/10644 [==============================] - 2s 228us/step - loss: 0.4183 - acc: 0.7998 - val_loss: 3.2567 - val_acc: 0.6667\n",
      "Epoch 29/100\n",
      "10644/10644 [==============================] - 3s 238us/step - loss: 0.4152 - acc: 0.8013 - val_loss: 3.2224 - val_acc: 0.6667\n",
      "Epoch 30/100\n",
      "10644/10644 [==============================] - 3s 250us/step - loss: 0.4147 - acc: 0.8014 - val_loss: 3.2679 - val_acc: 0.6667\n",
      "Epoch 31/100\n",
      "10644/10644 [==============================] - 2s 216us/step - loss: 0.4088 - acc: 0.8053 - val_loss: 3.3969 - val_acc: 0.5556\n",
      "Epoch 32/100\n",
      "10644/10644 [==============================] - 2s 217us/step - loss: 0.4083 - acc: 0.8049 - val_loss: 3.3645 - val_acc: 0.6667\n",
      "Epoch 33/100\n",
      "10644/10644 [==============================] - 2s 222us/step - loss: 0.4050 - acc: 0.8073 - val_loss: 3.5889 - val_acc: 0.5556\n",
      "Epoch 34/100\n",
      "10644/10644 [==============================] - 2s 220us/step - loss: 0.4049 - acc: 0.8098 - val_loss: 3.3031 - val_acc: 0.5185\n",
      "Epoch 35/100\n",
      "10644/10644 [==============================] - 2s 220us/step - loss: 0.4028 - acc: 0.8070 - val_loss: 3.3411 - val_acc: 0.6667\n",
      "Epoch 36/100\n",
      "10644/10644 [==============================] - 2s 211us/step - loss: 0.4011 - acc: 0.8108 - val_loss: 3.3730 - val_acc: 0.6667\n",
      "Epoch 37/100\n",
      "10644/10644 [==============================] - 2s 209us/step - loss: 0.3974 - acc: 0.8128 - val_loss: 3.1128 - val_acc: 0.7037\n",
      "Epoch 38/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3974 - acc: 0.8144 - val_loss: 3.3372 - val_acc: 0.6667\n",
      "Epoch 39/100\n",
      "10644/10644 [==============================] - 2s 193us/step - loss: 0.3937 - acc: 0.8124 - val_loss: 3.4344 - val_acc: 0.7037\n",
      "Epoch 40/100\n",
      "10644/10644 [==============================] - 2s 206us/step - loss: 0.3906 - acc: 0.8136 - val_loss: 3.3461 - val_acc: 0.7037\n",
      "Epoch 41/100\n",
      "10644/10644 [==============================] - 2s 217us/step - loss: 0.3871 - acc: 0.8178 - val_loss: 3.1695 - val_acc: 0.6667\n",
      "Epoch 42/100\n",
      "10644/10644 [==============================] - 2s 210us/step - loss: 0.3864 - acc: 0.8177 - val_loss: 3.4084 - val_acc: 0.7037\n",
      "Epoch 43/100\n",
      "10644/10644 [==============================] - 2s 214us/step - loss: 0.3857 - acc: 0.8161 - val_loss: 3.0837 - val_acc: 0.6667\n",
      "Epoch 44/100\n",
      "10644/10644 [==============================] - 2s 204us/step - loss: 0.3824 - acc: 0.8187 - val_loss: 3.1875 - val_acc: 0.6296\n",
      "Epoch 45/100\n",
      "10644/10644 [==============================] - 2s 201us/step - loss: 0.3832 - acc: 0.8203 - val_loss: 3.1727 - val_acc: 0.7407\n",
      "Epoch 46/100\n",
      "10644/10644 [==============================] - 2s 203us/step - loss: 0.3789 - acc: 0.8222 - val_loss: 3.0813 - val_acc: 0.6296\n",
      "Epoch 47/100\n",
      "10644/10644 [==============================] - 2s 228us/step - loss: 0.3783 - acc: 0.8200 - val_loss: 3.4927 - val_acc: 0.6296\n",
      "Epoch 48/100\n",
      "10644/10644 [==============================] - 2s 201us/step - loss: 0.3813 - acc: 0.8210 - val_loss: 3.4009 - val_acc: 0.7407\n",
      "Epoch 49/100\n",
      "10644/10644 [==============================] - 2s 225us/step - loss: 0.3745 - acc: 0.8236 - val_loss: 3.3630 - val_acc: 0.6667\n",
      "Epoch 50/100\n",
      "10644/10644 [==============================] - 2s 210us/step - loss: 0.3734 - acc: 0.8240 - val_loss: 3.5105 - val_acc: 0.6296\n",
      "Epoch 51/100\n",
      "10644/10644 [==============================] - 2s 208us/step - loss: 0.3770 - acc: 0.8226 - val_loss: 3.5066 - val_acc: 0.7407\n",
      "Epoch 52/100\n",
      "10644/10644 [==============================] - 2s 204us/step - loss: 0.3745 - acc: 0.8216 - val_loss: 3.4118 - val_acc: 0.6667\n",
      "Epoch 53/100\n",
      "10644/10644 [==============================] - 2s 205us/step - loss: 0.3700 - acc: 0.8255 - val_loss: 3.4408 - val_acc: 0.7407\n",
      "Epoch 54/100\n",
      "10644/10644 [==============================] - 2s 225us/step - loss: 0.3690 - acc: 0.8270 - val_loss: 3.3796 - val_acc: 0.7407\n",
      "Epoch 55/100\n",
      "10644/10644 [==============================] - 2s 206us/step - loss: 0.3682 - acc: 0.8267 - val_loss: 3.3765 - val_acc: 0.7407\n",
      "Epoch 56/100\n",
      "10644/10644 [==============================] - 2s 205us/step - loss: 0.3676 - acc: 0.8233 - val_loss: 3.4806 - val_acc: 0.6667\n",
      "Epoch 57/100\n",
      "10644/10644 [==============================] - 2s 197us/step - loss: 0.3679 - acc: 0.8238 - val_loss: 3.5172 - val_acc: 0.6667\n",
      "Epoch 58/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3663 - acc: 0.8270 - val_loss: 3.5129 - val_acc: 0.6296\n",
      "Epoch 59/100\n",
      "10644/10644 [==============================] - 2s 209us/step - loss: 0.3636 - acc: 0.8287 - val_loss: 3.4703 - val_acc: 0.6296\n",
      "Epoch 60/100\n",
      "10644/10644 [==============================] - 2s 212us/step - loss: 0.3626 - acc: 0.8283 - val_loss: 3.4172 - val_acc: 0.6296\n",
      "Epoch 61/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3624 - acc: 0.8280 - val_loss: 3.4014 - val_acc: 0.7407\n",
      "Epoch 62/100\n",
      "10644/10644 [==============================] - 2s 212us/step - loss: 0.3597 - acc: 0.8284 - val_loss: 3.5346 - val_acc: 0.6296\n",
      "Epoch 63/100\n",
      "10644/10644 [==============================] - 2s 196us/step - loss: 0.3602 - acc: 0.8320 - val_loss: 3.4463 - val_acc: 0.7037\n",
      "Epoch 64/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3592 - acc: 0.8278 - val_loss: 3.3793 - val_acc: 0.7407\n",
      "Epoch 65/100\n",
      "10644/10644 [==============================] - 2s 225us/step - loss: 0.3590 - acc: 0.8289 - val_loss: 3.4337 - val_acc: 0.6667\n",
      "Epoch 66/100\n",
      "10644/10644 [==============================] - 2s 208us/step - loss: 0.3548 - acc: 0.8308 - val_loss: 3.4900 - val_acc: 0.6667\n",
      "Epoch 67/100\n",
      "10644/10644 [==============================] - 3s 250us/step - loss: 0.3565 - acc: 0.8297 - val_loss: 3.3746 - val_acc: 0.7407\n",
      "Epoch 68/100\n",
      "10644/10644 [==============================] - 2s 221us/step - loss: 0.3550 - acc: 0.8304 - val_loss: 3.4522 - val_acc: 0.6667\n",
      "Epoch 69/100\n",
      "10644/10644 [==============================] - 2s 235us/step - loss: 0.3555 - acc: 0.8298 - val_loss: 3.4298 - val_acc: 0.6296\n",
      "Epoch 70/100\n",
      "10644/10644 [==============================] - 3s 278us/step - loss: 0.3521 - acc: 0.8325 - val_loss: 3.4853 - val_acc: 0.7407\n",
      "Epoch 71/100\n",
      "10644/10644 [==============================] - 2s 234us/step - loss: 0.3526 - acc: 0.8326 - val_loss: 3.5285 - val_acc: 0.6667\n",
      "Epoch 72/100\n",
      "10644/10644 [==============================] - 2s 184us/step - loss: 0.3542 - acc: 0.8300 - val_loss: 3.3986 - val_acc: 0.7407\n",
      "Epoch 73/100\n",
      "10644/10644 [==============================] - 2s 216us/step - loss: 0.3463 - acc: 0.8349 - val_loss: 3.5745 - val_acc: 0.7037\n",
      "Epoch 74/100\n",
      "10644/10644 [==============================] - 2s 182us/step - loss: 0.3511 - acc: 0.8342 - val_loss: 3.5187 - val_acc: 0.7407\n",
      "Epoch 75/100\n",
      "10644/10644 [==============================] - 2s 187us/step - loss: 0.3480 - acc: 0.8347 - val_loss: 3.6018 - val_acc: 0.6667\n",
      "Epoch 76/100\n",
      "10644/10644 [==============================] - 2s 192us/step - loss: 0.3481 - acc: 0.8358 - val_loss: 3.4607 - val_acc: 0.6667\n",
      "Epoch 77/100\n",
      "10644/10644 [==============================] - 2s 226us/step - loss: 0.3525 - acc: 0.8324 - val_loss: 3.7976 - val_acc: 0.6667\n",
      "Epoch 78/100\n",
      "10644/10644 [==============================] - 2s 225us/step - loss: 0.3438 - acc: 0.8340 - val_loss: 3.4692 - val_acc: 0.7407\n",
      "Epoch 79/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3431 - acc: 0.8361 - val_loss: 3.5411 - val_acc: 0.6667\n",
      "Epoch 80/100\n",
      "10644/10644 [==============================] - 3s 244us/step - loss: 0.3458 - acc: 0.8354 - val_loss: 3.7983 - val_acc: 0.6296\n",
      "Epoch 81/100\n",
      "10644/10644 [==============================] - 2s 207us/step - loss: 0.3451 - acc: 0.8355 - val_loss: 3.5221 - val_acc: 0.7407\n",
      "Epoch 82/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3408 - acc: 0.8371 - val_loss: 3.3639 - val_acc: 0.7407\n",
      "Epoch 83/100\n",
      "10644/10644 [==============================] - 2s 181us/step - loss: 0.3441 - acc: 0.8349 - val_loss: 3.4996 - val_acc: 0.7407\n",
      "Epoch 84/100\n",
      "10644/10644 [==============================] - 2s 185us/step - loss: 0.3390 - acc: 0.8390 - val_loss: 3.8983 - val_acc: 0.6667\n",
      "Epoch 85/100\n",
      "10644/10644 [==============================] - 2s 187us/step - loss: 0.3406 - acc: 0.8424 - val_loss: 3.8116 - val_acc: 0.6667\n",
      "Epoch 86/100\n",
      "10644/10644 [==============================] - 2s 188us/step - loss: 0.3370 - acc: 0.8395 - val_loss: 3.3902 - val_acc: 0.7037\n",
      "Epoch 87/100\n",
      "10644/10644 [==============================] - 2s 210us/step - loss: 0.3372 - acc: 0.8393 - val_loss: 3.4978 - val_acc: 0.6667\n",
      "Epoch 88/100\n",
      "10644/10644 [==============================] - 2s 187us/step - loss: 0.3409 - acc: 0.8384 - val_loss: 4.0747 - val_acc: 0.6667\n",
      "Epoch 89/100\n",
      "10644/10644 [==============================] - 2s 197us/step - loss: 0.3408 - acc: 0.8391 - val_loss: 3.7106 - val_acc: 0.7037\n",
      "Epoch 90/100\n",
      "10644/10644 [==============================] - 2s 194us/step - loss: 0.3328 - acc: 0.8455 - val_loss: 3.8505 - val_acc: 0.6296\n",
      "Epoch 91/100\n",
      "10644/10644 [==============================] - 2s 196us/step - loss: 0.3354 - acc: 0.8404 - val_loss: 3.4489 - val_acc: 0.6667\n",
      "Epoch 92/100\n",
      "10644/10644 [==============================] - 2s 202us/step - loss: 0.3327 - acc: 0.8421 - val_loss: 3.5462 - val_acc: 0.7407\n",
      "Epoch 93/100\n",
      "10644/10644 [==============================] - 2s 225us/step - loss: 0.3317 - acc: 0.8439 - val_loss: 3.6970 - val_acc: 0.6667\n",
      "Epoch 94/100\n",
      "10644/10644 [==============================] - 2s 200us/step - loss: 0.3327 - acc: 0.8411 - val_loss: 3.5927 - val_acc: 0.6667\n",
      "Epoch 95/100\n",
      "10644/10644 [==============================] - 2s 197us/step - loss: 0.3298 - acc: 0.8446 - val_loss: 3.5202 - val_acc: 0.7407\n",
      "Epoch 96/100\n",
      "10644/10644 [==============================] - 2s 194us/step - loss: 0.3291 - acc: 0.8440 - val_loss: 3.6142 - val_acc: 0.6667\n",
      "Epoch 97/100\n",
      "10644/10644 [==============================] - 2s 194us/step - loss: 0.3305 - acc: 0.8425 - val_loss: 3.8739 - val_acc: 0.6296\n",
      "Epoch 98/100\n",
      "10644/10644 [==============================] - 2s 182us/step - loss: 0.3366 - acc: 0.8396 - val_loss: 3.5231 - val_acc: 0.7407\n",
      "Epoch 99/100\n",
      "10644/10644 [==============================] - 2s 190us/step - loss: 0.3284 - acc: 0.8426 - val_loss: 3.7286 - val_acc: 0.6667\n",
      "Epoch 100/100\n",
      "10644/10644 [==============================] - 2s 185us/step - loss: 0.3256 - acc: 0.8450 - val_loss: 4.1806 - val_acc: 0.6296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7f44c20b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_std,Y, batch_size=10, epochs=100,validation_data=(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-51f0dcd37a78>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-51f0dcd37a78>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print classification_report(y_pred, Y_test)\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_pred= classifier.predict(X_test_std)\n",
    "y_pred =(y_pred>0.5)\n",
    "print classification_report(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_std_, X_test_std_, y_train_std_, y_test_std_ = train_test_split(X_std, Y, test_size=0.33, random_state=42)\n",
    "print(len(X_train_std_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8144036436094506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=4, n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_std_,y_train_std_)\n",
    "print(clf.score(X_test_std_, y_test_std_))\n",
    "#print(clf.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2, n_estimators:  10, score: 0.687, sc: [0.669, 0.698, 0.688, 0.653, 0.685]\n",
      "max_depth: 2, n_estimators:  25, score: 0.722, sc: [0.697, 0.738, 0.687, 0.698, 0.709]\n",
      "max_depth: 2, n_estimators:  50, score: 0.779, sc: [0.771, 0.758, 0.698, 0.721, 0.738]\n",
      "max_depth: 2, n_estimators: 100, score: 0.775, sc: [0.808, 0.774, 0.764, 0.735, 0.769]\n",
      "max_depth: 2, n_estimators: 200, score: 0.798, sc: [0.805, 0.765, 0.785, 0.750, 0.769]\n",
      "max_depth: 3, n_estimators:  10, score: 0.762, sc: [0.693, 0.751, 0.744, 0.735, 0.739]\n",
      "max_depth: 3, n_estimators:  25, score: 0.792, sc: [0.815, 0.798, 0.760, 0.747, 0.745]\n",
      "max_depth: 3, n_estimators:  50, score: 0.807, sc: [0.822, 0.804, 0.807, 0.740, 0.786]\n",
      "max_depth: 3, n_estimators: 100, score: 0.814, sc: [0.811, 0.809, 0.805, 0.758, 0.793]\n",
      "max_depth: 3, n_estimators: 200, score: 0.816, sc: [0.815, 0.811, 0.794, 0.752, 0.800]\n",
      "max_depth: 4, n_estimators:  10, score: 0.777, sc: [0.804, 0.792, 0.768, 0.748, 0.759]\n",
      "max_depth: 4, n_estimators:  25, score: 0.804, sc: [0.836, 0.807, 0.799, 0.754, 0.779]\n",
      "max_depth: 4, n_estimators:  50, score: 0.810, sc: [0.831, 0.804, 0.802, 0.761, 0.786]\n",
      "max_depth: 4, n_estimators: 100, score: 0.814, sc: [0.819, 0.819, 0.814, 0.762, 0.796]\n",
      "max_depth: 4, n_estimators: 200, score: 0.812, sc: [0.808, 0.818, 0.814, 0.764, 0.806]\n",
      "max_depth: 5, n_estimators:  10, score: 0.798, sc: [0.822, 0.777, 0.767, 0.761, 0.773]\n",
      "max_depth: 5, n_estimators:  25, score: 0.809, sc: [0.844, 0.802, 0.805, 0.765, 0.785]\n",
      "max_depth: 5, n_estimators:  50, score: 0.816, sc: [0.838, 0.802, 0.802, 0.768, 0.796]\n",
      "max_depth: 5, n_estimators: 100, score: 0.818, sc: [0.821, 0.799, 0.792, 0.760, 0.806]\n",
      "max_depth: 5, n_estimators: 200, score: 0.815, sc: [0.798, 0.791, 0.795, 0.754, 0.795]\n",
      "max_depth: 6, n_estimators:  10, score: 0.796, sc: [0.838, 0.798, 0.788, 0.757, 0.780]\n",
      "max_depth: 6, n_estimators:  25, score: 0.811, sc: [0.828, 0.812, 0.817, 0.761, 0.800]\n",
      "max_depth: 6, n_estimators:  50, score: 0.810, sc: [0.817, 0.815, 0.808, 0.764, 0.803]\n",
      "max_depth: 6, n_estimators: 100, score: 0.814, sc: [0.818, 0.812, 0.799, 0.757, 0.800]\n",
      "max_depth: 6, n_estimators: 200, score: 0.814, sc: [0.815, 0.811, 0.795, 0.754, 0.802]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#?GradientBoostingClassifier\n",
    "for md in [2,3,4,5,6]:\n",
    "    for ne in [10,25,50,100,200]:\n",
    "        clf = GradientBoostingClassifier(max_depth=md,n_estimators=ne, random_state=42)\n",
    "        clf.fit(X_train_std_,y_train_std_)\n",
    "        scores = cross_val_score(clf,  X_test_std_, y_test_std_, cv=5)\n",
    "        print(\"max_depth: %d, n_estimators: %3d, score: %.3f, sc: [%s]\" % \n",
    "              (md, ne, clf.score(X_test_std_, y_test_std_), ', '.join(map(lambda t: '%.3f' % t,scores.tolist()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential() \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal', input_dim=len(X_std[0]))) \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7131 samples, validate on 3513 samples\n",
      "Epoch 1/10\n",
      "7131/7131 [==============================] - 2s 266us/step - loss: 0.3916 - acc: 0.8114 - val_loss: 0.4596 - val_acc: 0.7945\n",
      "Epoch 2/10\n",
      "7131/7131 [==============================] - 2s 252us/step - loss: 0.3896 - acc: 0.8162 - val_loss: 0.4463 - val_acc: 0.8061\n",
      "Epoch 3/10\n",
      "7131/7131 [==============================] - 2s 256us/step - loss: 0.3876 - acc: 0.8150 - val_loss: 0.4538 - val_acc: 0.7993\n",
      "Epoch 4/10\n",
      "7131/7131 [==============================] - 2s 236us/step - loss: 0.3885 - acc: 0.8155 - val_loss: 0.4546 - val_acc: 0.8002\n",
      "Epoch 5/10\n",
      "7131/7131 [==============================] - 2s 237us/step - loss: 0.3872 - acc: 0.8145 - val_loss: 0.4422 - val_acc: 0.8076\n",
      "Epoch 6/10\n",
      "7131/7131 [==============================] - 2s 226us/step - loss: 0.3827 - acc: 0.8153 - val_loss: 0.4472 - val_acc: 0.8053\n",
      "Epoch 7/10\n",
      "7131/7131 [==============================] - 2s 238us/step - loss: 0.3785 - acc: 0.8208 - val_loss: 0.4566 - val_acc: 0.8033\n",
      "Epoch 8/10\n",
      "7131/7131 [==============================] - 2s 243us/step - loss: 0.3811 - acc: 0.8178 - val_loss: 0.4578 - val_acc: 0.8087\n",
      "Epoch 9/10\n",
      "7131/7131 [==============================] - 2s 262us/step - loss: 0.3780 - acc: 0.8181 - val_loss: 0.4666 - val_acc: 0.8022\n",
      "Epoch 10/10\n",
      "7131/7131 [==============================] - 2s 237us/step - loss: 0.3725 - acc: 0.8233 - val_loss: 0.4507 - val_acc: 0.8059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7f02bcd68>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_std_,y_train_std_, batch_size=10, epochs=10,validation_data=(X_test_std_, y_test_std_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.82      0.76      1356\n",
      "        True       0.87      0.80      0.83      2157\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      3513\n",
      "   macro avg       0.79      0.81      0.80      3513\n",
      "weighted avg       0.81      0.80      0.81      3513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= classifier.predict(X_test_std_)\n",
    "y_pred =(y_pred>0.5)\n",
    "print( classification_report(y_pred, y_test_std_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
