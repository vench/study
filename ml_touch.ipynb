{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Touch\n",
    "\n",
    "Имеем два набора данных. один набор размечен пользователями 28 примеров, второй набор размечан автоматически 3188.\n",
    "\n",
    "Проверим, насколько автоматически полученные данные, хорошо описывают размеченные вручную.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pn\n",
    "import numpy as np\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: 15\n"
     ]
    }
   ],
   "source": [
    "file_name_user = 'data_sets/mphone_mark_users.csv'\n",
    "file_name_auto = 'data_sets/mphone_mark_auto.csv'\n",
    "\n",
    "#?pn.read_csv\n",
    "columns = [\"Gender\",\"Fingerprint\",\"TimeUpx\",\"W\",\"H\",\"leng\",\"leng_sum\",\"speed\",\"Force\",\"ForceUp\",\"Rx\",\"Ry\",\"varX\",\"varY\",\"coorXY\"]\n",
    "print('columns: %d' % len(columns))\n",
    "df_user = pn.read_csv(file_name_user, nrows=15000, names=columns, header=1)\n",
    "df_auto = pn.read_csv(file_name_auto, nrows=15000, names=columns, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeUpx</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>leng</th>\n",
       "      <th>leng_sum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Force</th>\n",
       "      <th>ForceUp</th>\n",
       "      <th>Rx</th>\n",
       "      <th>Ry</th>\n",
       "      <th>varX</th>\n",
       "      <th>varY</th>\n",
       "      <th>coorXY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>373.723473</td>\n",
       "      <td>350.370370</td>\n",
       "      <td>662.592593</td>\n",
       "      <td>177.994823</td>\n",
       "      <td>1216.167096</td>\n",
       "      <td>0.483212</td>\n",
       "      <td>0.452393</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>12.715362</td>\n",
       "      <td>12.715362</td>\n",
       "      <td>2086.672672</td>\n",
       "      <td>1.793523e+05</td>\n",
       "      <td>-0.146530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>302.411272</td>\n",
       "      <td>20.751549</td>\n",
       "      <td>75.541257</td>\n",
       "      <td>296.190706</td>\n",
       "      <td>1043.608911</td>\n",
       "      <td>0.349451</td>\n",
       "      <td>0.499913</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>15.919060</td>\n",
       "      <td>15.919060</td>\n",
       "      <td>3643.059642</td>\n",
       "      <td>4.694765e+05</td>\n",
       "      <td>0.720704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>24.745730</td>\n",
       "      <td>77.820310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.715000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>568.000000</td>\n",
       "      <td>50.585805</td>\n",
       "      <td>386.837215</td>\n",
       "      <td>0.193145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.070085</td>\n",
       "      <td>7.912361e+02</td>\n",
       "      <td>-0.830993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>295.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>108.321700</td>\n",
       "      <td>720.271370</td>\n",
       "      <td>0.434170</td>\n",
       "      <td>0.056330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.659180</td>\n",
       "      <td>538.249140</td>\n",
       "      <td>4.420800e+03</td>\n",
       "      <td>-0.164595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>454.083335</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>740.000000</td>\n",
       "      <td>147.380345</td>\n",
       "      <td>2233.540275</td>\n",
       "      <td>0.757295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.601315</td>\n",
       "      <td>28.601315</td>\n",
       "      <td>2109.694450</td>\n",
       "      <td>1.430145e+05</td>\n",
       "      <td>0.562660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1385.666670</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>1591.342210</td>\n",
       "      <td>3439.153620</td>\n",
       "      <td>1.155530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031670</td>\n",
       "      <td>44.886670</td>\n",
       "      <td>44.886670</td>\n",
       "      <td>14559.183400</td>\n",
       "      <td>2.301841e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TimeUpx           W           H         leng     leng_sum  \\\n",
       "count    27.000000   27.000000   27.000000    27.000000    27.000000   \n",
       "mean    373.723473  350.370370  662.592593   177.994823  1216.167096   \n",
       "std     302.411272   20.751549   75.541257   296.190706  1043.608911   \n",
       "min       0.000000  320.000000  568.000000    24.745730    77.820310   \n",
       "25%     184.715000  320.000000  568.000000    50.585805   386.837215   \n",
       "50%     295.000000  360.000000  667.000000   108.321700   720.271370   \n",
       "75%     454.083335  360.000000  740.000000   147.380345  2233.540275   \n",
       "max    1385.666670  375.000000  760.000000  1591.342210  3439.153620   \n",
       "\n",
       "           speed      Force    ForceUp         Rx         Ry          varX  \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000     27.000000   \n",
       "mean    0.483212   0.452393   0.002481  12.715362  12.715362   2086.672672   \n",
       "std     0.349451   0.499913   0.007526  15.919060  15.919060   3643.059642   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000      0.000000   \n",
       "25%     0.193145   0.000000   0.000000   0.000000   0.000000    113.070085   \n",
       "50%     0.434170   0.056330   0.000000   0.659180   0.659180    538.249140   \n",
       "75%     0.757295   1.000000   0.000000  28.601315  28.601315   2109.694450   \n",
       "max     1.155530   1.000000   0.031670  44.886670  44.886670  14559.183400   \n",
       "\n",
       "               varY     coorXY  \n",
       "count  2.700000e+01  24.000000  \n",
       "mean   1.793523e+05  -0.146530  \n",
       "std    4.694765e+05   0.720704  \n",
       "min    0.000000e+00  -1.000000  \n",
       "25%    7.912361e+02  -0.830993  \n",
       "50%    4.420800e+03  -0.164595  \n",
       "75%    1.430145e+05   0.562660  \n",
       "max    2.301841e+06   1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeUpx</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>leng</th>\n",
       "      <th>leng_sum</th>\n",
       "      <th>speed</th>\n",
       "      <th>Force</th>\n",
       "      <th>ForceUp</th>\n",
       "      <th>Rx</th>\n",
       "      <th>Ry</th>\n",
       "      <th>varX</th>\n",
       "      <th>varY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "      <td>3188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>771.764652</td>\n",
       "      <td>368.568346</td>\n",
       "      <td>639.807897</td>\n",
       "      <td>138.054755</td>\n",
       "      <td>2264.775905</td>\n",
       "      <td>0.359535</td>\n",
       "      <td>0.803830</td>\n",
       "      <td>0.070930</td>\n",
       "      <td>2.168585</td>\n",
       "      <td>2.204334</td>\n",
       "      <td>1788.098974</td>\n",
       "      <td>3122.489911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1171.353036</td>\n",
       "      <td>77.293368</td>\n",
       "      <td>68.062270</td>\n",
       "      <td>73.612584</td>\n",
       "      <td>2623.534999</td>\n",
       "      <td>0.298511</td>\n",
       "      <td>0.365201</td>\n",
       "      <td>0.252262</td>\n",
       "      <td>3.192029</td>\n",
       "      <td>3.179487</td>\n",
       "      <td>6511.340500</td>\n",
       "      <td>4394.646649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>243.895837</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>83.697188</td>\n",
       "      <td>856.507152</td>\n",
       "      <td>0.205483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111.687115</td>\n",
       "      <td>562.264833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>460.525645</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>120.338900</td>\n",
       "      <td>1535.639780</td>\n",
       "      <td>0.318375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.708340</td>\n",
       "      <td>0.793565</td>\n",
       "      <td>343.992190</td>\n",
       "      <td>1638.736115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>854.645243</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>174.479582</td>\n",
       "      <td>2638.827905</td>\n",
       "      <td>0.454695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.291508</td>\n",
       "      <td>3.291508</td>\n",
       "      <td>1108.977437</td>\n",
       "      <td>3897.983607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20662.000000</td>\n",
       "      <td>1280.000000</td>\n",
       "      <td>1280.000000</td>\n",
       "      <td>584.874850</td>\n",
       "      <td>34518.969310</td>\n",
       "      <td>10.135830</td>\n",
       "      <td>1.091670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.575510</td>\n",
       "      <td>22.575510</td>\n",
       "      <td>198307.582230</td>\n",
       "      <td>51175.770670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TimeUpx            W            H         leng      leng_sum  \\\n",
       "count   3188.000000  3188.000000  3188.000000  3188.000000   3188.000000   \n",
       "mean     771.764652   368.568346   639.807897   138.054755   2264.775905   \n",
       "std     1171.353036    77.293368    68.062270    73.612584   2623.534999   \n",
       "min        0.000000   320.000000   320.000000     0.000000      0.000000   \n",
       "25%      243.895837   360.000000   640.000000    83.697188    856.507152   \n",
       "50%      460.525645   360.000000   640.000000   120.338900   1535.639780   \n",
       "75%      854.645243   360.000000   640.000000   174.479582   2638.827905   \n",
       "max    20662.000000  1280.000000  1280.000000   584.874850  34518.969310   \n",
       "\n",
       "             speed        Force      ForceUp           Rx           Ry  \\\n",
       "count  3188.000000  3188.000000  3188.000000  3188.000000  3188.000000   \n",
       "mean      0.359535     0.803830     0.070930     2.168585     2.204334   \n",
       "std       0.298511     0.365201     0.252262     3.192029     3.179487   \n",
       "min       0.000000     0.003930     0.000000     0.000000     0.000000   \n",
       "25%       0.205483     1.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.318375     1.000000     0.000000     0.708340     0.793565   \n",
       "75%       0.454695     1.000000     0.000000     3.291508     3.291508   \n",
       "max      10.135830     1.091670     1.000000    22.575510    22.575510   \n",
       "\n",
       "                varX          varY  \n",
       "count    3188.000000   3188.000000  \n",
       "mean     1788.098974   3122.489911  \n",
       "std      6511.340500   4394.646649  \n",
       "min         0.000000      0.000000  \n",
       "25%       111.687115    562.264833  \n",
       "50%       343.992190   1638.736115  \n",
       "75%      1108.977437   3897.983607  \n",
       "max    198307.582230  51175.770670  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df_user = df_user.fillna(0)\n",
    "df_auto = df_auto.fillna(0)\n",
    "\n",
    "def map_target(cl):\n",
    "    if(cl == 'f'):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "X = df_auto[columns[2:]]\n",
    "X_test =df_user[columns[2:]]\n",
    "Y = df_auto['Gender'].map(map_target)\n",
    "Y_test = df_user['Gender'].map(map_target) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20, max_depth=4, random_state=0)\n",
    "clf.fit(X_std,Y)\n",
    "print(clf.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.22      0.40      0.29         5\n",
      "          1       0.83      0.68      0.75        22\n",
      "\n",
      "avg / total       0.72      0.63      0.66        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(clf.predict(X_test_std), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=2, n_estimators=25, random_state=42)\n",
    "clf.fit(X_std,Y)\n",
    "print(clf.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.44      0.44         9\n",
      "          1       0.72      0.72      0.72        18\n",
      "\n",
      "avg / total       0.63      0.63      0.63        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(clf.predict(X_test_std), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2, n_estimators:  10, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 2, n_estimators:  25, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 2, n_estimators:  50, score: 0.667, m-score: 0.653, sc: [0.667, 0.667, 0.833, 0.600, 0.500]\n",
      "max_depth: 2, n_estimators: 100, score: 0.593, m-score: 0.653, sc: [0.833, 0.667, 0.667, 0.600, 0.500]\n",
      "max_depth: 2, n_estimators: 200, score: 0.481, m-score: 0.743, sc: [0.833, 0.667, 0.667, 0.800, 0.750]\n",
      "max_depth: 3, n_estimators:  10, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators:  25, score: 0.630, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators:  50, score: 0.630, m-score: 0.693, sc: [0.833, 0.667, 0.667, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators: 100, score: 0.630, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 3, n_estimators: 200, score: 0.630, m-score: 0.727, sc: [0.833, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators:  10, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators:  25, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators:  50, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators: 100, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 4, n_estimators: 200, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators:  10, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators:  25, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators:  50, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators: 100, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 5, n_estimators: 200, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators:  10, score: 0.667, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators:  25, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators:  50, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators: 100, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n",
      "max_depth: 6, n_estimators: 200, score: 0.630, m-score: 0.693, sc: [0.667, 0.667, 0.833, 0.800, 0.500]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#?GradientBoostingClassifier\n",
    "for md in [2,3,4,5,6]:\n",
    "    for ne in [10,25,50,100,200]:\n",
    "        clf = GradientBoostingClassifier(max_depth=md,n_estimators=ne, random_state=42)\n",
    "        clf.fit(X_std,Y)\n",
    "        sc = clf.score(X_test_std, Y_test)\n",
    "        scores = cross_val_score(clf,  X_test_std, Y_test, cv=5)\n",
    "        print(\"max_depth: %d, n_estimators: %3d, score: %.3f, m-score: %.3f, sc: [%s]\" % \n",
    "              (md, ne, sc, scores.mean(), ', '.join(map(lambda t: '%.3f' % t,scores.tolist()))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  NN keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential() \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal', input_dim=len(X_std[0]))) \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4713 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "4713/4713 [==============================] - 1s 222us/step - loss: 0.6526 - acc: 0.6287 - val_loss: 1.6151 - val_acc: 0.5185\n",
      "Epoch 2/100\n",
      "4713/4713 [==============================] - 1s 190us/step - loss: 0.6136 - acc: 0.6722 - val_loss: 1.6351 - val_acc: 0.4444\n",
      "Epoch 3/100\n",
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.5711 - acc: 0.6970 - val_loss: 2.0860 - val_acc: 0.4074\n",
      "Epoch 4/100\n",
      "4713/4713 [==============================] - 1s 187us/step - loss: 0.5549 - acc: 0.7066 - val_loss: 2.2888 - val_acc: 0.4074\n",
      "Epoch 5/100\n",
      "4713/4713 [==============================] - 1s 205us/step - loss: 0.5436 - acc: 0.7159 - val_loss: 2.2843 - val_acc: 0.4074\n",
      "Epoch 6/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.5348 - acc: 0.7223 - val_loss: 2.3146 - val_acc: 0.4444\n",
      "Epoch 7/100\n",
      "4713/4713 [==============================] - 1s 187us/step - loss: 0.5277 - acc: 0.7269 - val_loss: 2.3760 - val_acc: 0.4444\n",
      "Epoch 8/100\n",
      "4713/4713 [==============================] - 1s 193us/step - loss: 0.5102 - acc: 0.7422 - val_loss: 2.4874 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.5049 - acc: 0.7456 - val_loss: 2.6083 - val_acc: 0.5185\n",
      "Epoch 10/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.4863 - acc: 0.7609 - val_loss: 2.7405 - val_acc: 0.5185\n",
      "Epoch 11/100\n",
      "4713/4713 [==============================] - 1s 208us/step - loss: 0.4752 - acc: 0.7672 - val_loss: 2.7319 - val_acc: 0.5926\n",
      "Epoch 12/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.4660 - acc: 0.7815 - val_loss: 2.9211 - val_acc: 0.5185\n",
      "Epoch 13/100\n",
      "4713/4713 [==============================] - 1s 195us/step - loss: 0.4537 - acc: 0.7825 - val_loss: 3.0425 - val_acc: 0.4815\n",
      "Epoch 14/100\n",
      "4713/4713 [==============================] - 1s 204us/step - loss: 0.4552 - acc: 0.7876 - val_loss: 3.0236 - val_acc: 0.5556\n",
      "Epoch 15/100\n",
      "4713/4713 [==============================] - 1s 210us/step - loss: 0.4462 - acc: 0.7908 - val_loss: 3.1458 - val_acc: 0.5185\n",
      "Epoch 16/100\n",
      "4713/4713 [==============================] - 1s 191us/step - loss: 0.4409 - acc: 0.7944 - val_loss: 3.1431 - val_acc: 0.5556\n",
      "Epoch 17/100\n",
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.4399 - acc: 0.7948 - val_loss: 3.4248 - val_acc: 0.5556\n",
      "Epoch 18/100\n",
      "4713/4713 [==============================] - 1s 195us/step - loss: 0.4357 - acc: 0.7976 - val_loss: 3.3739 - val_acc: 0.5185\n",
      "Epoch 19/100\n",
      "4713/4713 [==============================] - 1s 198us/step - loss: 0.4337 - acc: 0.7946 - val_loss: 3.4020 - val_acc: 0.5556\n",
      "Epoch 20/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.4365 - acc: 0.7908 - val_loss: 3.4954 - val_acc: 0.5185\n",
      "Epoch 21/100\n",
      "4713/4713 [==============================] - 1s 206us/step - loss: 0.4279 - acc: 0.7950 - val_loss: 3.7030 - val_acc: 0.5185\n",
      "Epoch 22/100\n",
      "4713/4713 [==============================] - 1s 197us/step - loss: 0.4240 - acc: 0.8029 - val_loss: 3.6005 - val_acc: 0.5556\n",
      "Epoch 23/100\n",
      "4713/4713 [==============================] - 1s 199us/step - loss: 0.4260 - acc: 0.8010 - val_loss: 3.5461 - val_acc: 0.5556\n",
      "Epoch 24/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.4230 - acc: 0.8012 - val_loss: 3.5373 - val_acc: 0.5556\n",
      "Epoch 25/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.4226 - acc: 0.8003 - val_loss: 3.5572 - val_acc: 0.5556\n",
      "Epoch 26/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.4193 - acc: 0.8061 - val_loss: 3.5814 - val_acc: 0.5556\n",
      "Epoch 27/100\n",
      "4713/4713 [==============================] - 1s 199us/step - loss: 0.4151 - acc: 0.8061 - val_loss: 3.5602 - val_acc: 0.5556\n",
      "Epoch 28/100\n",
      "4713/4713 [==============================] - 1s 198us/step - loss: 0.4164 - acc: 0.8071 - val_loss: 3.6409 - val_acc: 0.5185\n",
      "Epoch 29/100\n",
      "4713/4713 [==============================] - 1s 199us/step - loss: 0.4134 - acc: 0.8069 - val_loss: 3.6761 - val_acc: 0.5556\n",
      "Epoch 30/100\n",
      "4713/4713 [==============================] - 1s 203us/step - loss: 0.4142 - acc: 0.8105 - val_loss: 3.6627 - val_acc: 0.5556\n",
      "Epoch 31/100\n",
      "4713/4713 [==============================] - 1s 200us/step - loss: 0.4113 - acc: 0.8095 - val_loss: 3.7632 - val_acc: 0.5556\n",
      "Epoch 32/100\n",
      "4713/4713 [==============================] - 1s 195us/step - loss: 0.4081 - acc: 0.8120 - val_loss: 3.7052 - val_acc: 0.5556\n",
      "Epoch 33/100\n",
      "4713/4713 [==============================] - 1s 212us/step - loss: 0.4091 - acc: 0.8095 - val_loss: 3.6498 - val_acc: 0.5926\n",
      "Epoch 34/100\n",
      "4713/4713 [==============================] - 1s 212us/step - loss: 0.4059 - acc: 0.8093 - val_loss: 3.6277 - val_acc: 0.5556\n",
      "Epoch 35/100\n",
      "4713/4713 [==============================] - 1s 199us/step - loss: 0.4011 - acc: 0.8158 - val_loss: 3.6908 - val_acc: 0.5185\n",
      "Epoch 36/100\n",
      "4713/4713 [==============================] - 1s 186us/step - loss: 0.4005 - acc: 0.8177 - val_loss: 3.6928 - val_acc: 0.5185\n",
      "Epoch 37/100\n",
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.3991 - acc: 0.8139 - val_loss: 3.8090 - val_acc: 0.4444\n",
      "Epoch 38/100\n",
      "4713/4713 [==============================] - 1s 195us/step - loss: 0.3972 - acc: 0.8201 - val_loss: 3.6887 - val_acc: 0.5556\n",
      "Epoch 39/100\n",
      "4713/4713 [==============================] - 1s 201us/step - loss: 0.3971 - acc: 0.8203 - val_loss: 3.7053 - val_acc: 0.5556\n",
      "Epoch 40/100\n",
      "4713/4713 [==============================] - 1s 195us/step - loss: 0.3883 - acc: 0.8228 - val_loss: 3.7019 - val_acc: 0.5556\n",
      "Epoch 41/100\n",
      "4713/4713 [==============================] - 1s 196us/step - loss: 0.3916 - acc: 0.8235 - val_loss: 3.6931 - val_acc: 0.4815\n",
      "Epoch 42/100\n",
      "4713/4713 [==============================] - 1s 204us/step - loss: 0.3856 - acc: 0.8281 - val_loss: 3.6515 - val_acc: 0.5556\n",
      "Epoch 43/100\n",
      "4713/4713 [==============================] - 1s 219us/step - loss: 0.3857 - acc: 0.8260 - val_loss: 3.7717 - val_acc: 0.5926\n",
      "Epoch 44/100\n",
      "4713/4713 [==============================] - 1s 212us/step - loss: 0.3841 - acc: 0.8271 - val_loss: 3.6860 - val_acc: 0.4815\n",
      "Epoch 45/100\n",
      "4713/4713 [==============================] - 1s 217us/step - loss: 0.3823 - acc: 0.8275 - val_loss: 3.6210 - val_acc: 0.5926\n",
      "Epoch 46/100\n",
      "4713/4713 [==============================] - 1s 213us/step - loss: 0.3821 - acc: 0.8264 - val_loss: 3.7183 - val_acc: 0.5556\n",
      "Epoch 47/100\n",
      "4713/4713 [==============================] - 1s 204us/step - loss: 0.3815 - acc: 0.8228 - val_loss: 3.6796 - val_acc: 0.5926\n",
      "Epoch 48/100\n",
      "4713/4713 [==============================] - 1s 257us/step - loss: 0.3776 - acc: 0.8266 - val_loss: 3.7066 - val_acc: 0.5556\n",
      "Epoch 49/100\n",
      "4713/4713 [==============================] - 1s 212us/step - loss: 0.3725 - acc: 0.8351 - val_loss: 3.7202 - val_acc: 0.5926\n",
      "Epoch 50/100\n",
      "4713/4713 [==============================] - 1s 223us/step - loss: 0.3729 - acc: 0.8332 - val_loss: 3.7116 - val_acc: 0.5926\n",
      "Epoch 51/100\n",
      "4713/4713 [==============================] - 1s 212us/step - loss: 0.3720 - acc: 0.8309 - val_loss: 3.8142 - val_acc: 0.5185\n",
      "Epoch 52/100\n",
      "4713/4713 [==============================] - 1s 210us/step - loss: 0.3670 - acc: 0.8322 - val_loss: 4.0139 - val_acc: 0.4444\n",
      "Epoch 53/100\n",
      "4713/4713 [==============================] - 1s 205us/step - loss: 0.3655 - acc: 0.8341 - val_loss: 3.9540 - val_acc: 0.5556\n",
      "Epoch 54/100\n",
      "4713/4713 [==============================] - 1s 206us/step - loss: 0.3641 - acc: 0.8351 - val_loss: 3.9811 - val_acc: 0.4815\n",
      "Epoch 55/100\n",
      "4713/4713 [==============================] - 1s 204us/step - loss: 0.3643 - acc: 0.8364 - val_loss: 3.9314 - val_acc: 0.5556\n",
      "Epoch 56/100\n",
      "4713/4713 [==============================] - 1s 225us/step - loss: 0.3626 - acc: 0.8332 - val_loss: 3.8394 - val_acc: 0.5556\n",
      "Epoch 57/100\n",
      "4713/4713 [==============================] - 1s 213us/step - loss: 0.3563 - acc: 0.8413 - val_loss: 3.6868 - val_acc: 0.5556\n",
      "Epoch 58/100\n",
      "4713/4713 [==============================] - 1s 224us/step - loss: 0.3556 - acc: 0.8366 - val_loss: 3.8711 - val_acc: 0.4444\n",
      "Epoch 59/100\n",
      "4713/4713 [==============================] - 1s 220us/step - loss: 0.3544 - acc: 0.8383 - val_loss: 3.7441 - val_acc: 0.5556\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.3509 - acc: 0.8445 - val_loss: 3.8078 - val_acc: 0.5926\n",
      "Epoch 61/100\n",
      "4713/4713 [==============================] - 1s 197us/step - loss: 0.3506 - acc: 0.8387 - val_loss: 3.7198 - val_acc: 0.6296\n",
      "Epoch 62/100\n",
      "4713/4713 [==============================] - 1s 193us/step - loss: 0.3464 - acc: 0.8411 - val_loss: 3.6254 - val_acc: 0.5926\n",
      "Epoch 63/100\n",
      "4713/4713 [==============================] - 1s 187us/step - loss: 0.3415 - acc: 0.8483 - val_loss: 3.8810 - val_acc: 0.4815\n",
      "Epoch 64/100\n",
      "4713/4713 [==============================] - 1s 186us/step - loss: 0.3442 - acc: 0.8474 - val_loss: 3.6917 - val_acc: 0.5926\n",
      "Epoch 65/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.3434 - acc: 0.8449 - val_loss: 3.8086 - val_acc: 0.5556\n",
      "Epoch 66/100\n",
      "4713/4713 [==============================] - 1s 191us/step - loss: 0.3397 - acc: 0.8462 - val_loss: 4.1213 - val_acc: 0.5556\n",
      "Epoch 67/100\n",
      "4713/4713 [==============================] - 1s 186us/step - loss: 0.3412 - acc: 0.8415 - val_loss: 3.9594 - val_acc: 0.5556\n",
      "Epoch 68/100\n",
      "4713/4713 [==============================] - 1s 191us/step - loss: 0.3387 - acc: 0.8494 - val_loss: 3.8695 - val_acc: 0.5185\n",
      "Epoch 69/100\n",
      "4713/4713 [==============================] - 1s 186us/step - loss: 0.3389 - acc: 0.8472 - val_loss: 3.8013 - val_acc: 0.5926\n",
      "Epoch 70/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.3326 - acc: 0.8466 - val_loss: 3.7518 - val_acc: 0.5185\n",
      "Epoch 71/100\n",
      "4713/4713 [==============================] - 1s 192us/step - loss: 0.3364 - acc: 0.8449 - val_loss: 3.8391 - val_acc: 0.5556\n",
      "Epoch 72/100\n",
      "4713/4713 [==============================] - 1s 191us/step - loss: 0.3345 - acc: 0.8466 - val_loss: 4.0829 - val_acc: 0.5185\n",
      "Epoch 73/100\n",
      "4713/4713 [==============================] - 1s 195us/step - loss: 0.3283 - acc: 0.8506 - val_loss: 4.0431 - val_acc: 0.5926\n",
      "Epoch 74/100\n",
      "4713/4713 [==============================] - 1s 207us/step - loss: 0.3267 - acc: 0.8485 - val_loss: 3.7852 - val_acc: 0.5926\n",
      "Epoch 75/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.3295 - acc: 0.8502 - val_loss: 3.9806 - val_acc: 0.6296\n",
      "Epoch 76/100\n",
      "4713/4713 [==============================] - 1s 196us/step - loss: 0.3264 - acc: 0.8502 - val_loss: 4.1098 - val_acc: 0.5185\n",
      "Epoch 77/100\n",
      "4713/4713 [==============================] - 1s 198us/step - loss: 0.3240 - acc: 0.8523 - val_loss: 4.2435 - val_acc: 0.5556\n",
      "Epoch 78/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.3250 - acc: 0.8491 - val_loss: 4.0235 - val_acc: 0.5556\n",
      "Epoch 79/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.3237 - acc: 0.8479 - val_loss: 4.0626 - val_acc: 0.5556\n",
      "Epoch 80/100\n",
      "4713/4713 [==============================] - 1s 199us/step - loss: 0.3176 - acc: 0.8521 - val_loss: 4.0568 - val_acc: 0.5556\n",
      "Epoch 81/100\n",
      "4713/4713 [==============================] - 1s 202us/step - loss: 0.3199 - acc: 0.8538 - val_loss: 4.0713 - val_acc: 0.5185\n",
      "Epoch 82/100\n",
      "4713/4713 [==============================] - 1s 201us/step - loss: 0.3186 - acc: 0.8525 - val_loss: 3.9738 - val_acc: 0.5926\n",
      "Epoch 83/100\n",
      "4713/4713 [==============================] - 1s 199us/step - loss: 0.3185 - acc: 0.8517 - val_loss: 4.1905 - val_acc: 0.5185\n",
      "Epoch 84/100\n",
      "4713/4713 [==============================] - 1s 201us/step - loss: 0.3104 - acc: 0.8525 - val_loss: 4.0371 - val_acc: 0.5556\n",
      "Epoch 85/100\n",
      "4713/4713 [==============================] - 1s 197us/step - loss: 0.3106 - acc: 0.8568 - val_loss: 4.0702 - val_acc: 0.5556\n",
      "Epoch 86/100\n",
      "4713/4713 [==============================] - 1s 239us/step - loss: 0.3117 - acc: 0.8566 - val_loss: 4.1138 - val_acc: 0.5185\n",
      "Epoch 87/100\n",
      "4713/4713 [==============================] - 1s 315us/step - loss: 0.3102 - acc: 0.8587 - val_loss: 4.1336 - val_acc: 0.5926\n",
      "Epoch 88/100\n",
      "4713/4713 [==============================] - 1s 271us/step - loss: 0.3067 - acc: 0.8602 - val_loss: 4.3368 - val_acc: 0.5185\n",
      "Epoch 89/100\n",
      "4713/4713 [==============================] - 1s 202us/step - loss: 0.3059 - acc: 0.8561 - val_loss: 3.6819 - val_acc: 0.5556\n",
      "Epoch 90/100\n",
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.3054 - acc: 0.8570 - val_loss: 3.7437 - val_acc: 0.5926\n",
      "Epoch 91/100\n",
      "4713/4713 [==============================] - 1s 190us/step - loss: 0.3048 - acc: 0.8617 - val_loss: 3.8927 - val_acc: 0.5556\n",
      "Epoch 92/100\n",
      "4713/4713 [==============================] - 1s 191us/step - loss: 0.3082 - acc: 0.8627 - val_loss: 4.2191 - val_acc: 0.5185\n",
      "Epoch 93/100\n",
      "4713/4713 [==============================] - 1s 185us/step - loss: 0.3018 - acc: 0.8591 - val_loss: 4.2605 - val_acc: 0.5556\n",
      "Epoch 94/100\n",
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.3040 - acc: 0.8591 - val_loss: 4.2640 - val_acc: 0.5185\n",
      "Epoch 95/100\n",
      "4713/4713 [==============================] - 1s 190us/step - loss: 0.2979 - acc: 0.8636 - val_loss: 4.2215 - val_acc: 0.5556\n",
      "Epoch 96/100\n",
      "4713/4713 [==============================] - 1s 187us/step - loss: 0.2957 - acc: 0.8655 - val_loss: 4.2733 - val_acc: 0.5185\n",
      "Epoch 97/100\n",
      "4713/4713 [==============================] - 1s 191us/step - loss: 0.2994 - acc: 0.8629 - val_loss: 4.5734 - val_acc: 0.5556\n",
      "Epoch 98/100\n",
      "4713/4713 [==============================] - 1s 189us/step - loss: 0.2936 - acc: 0.8644 - val_loss: 4.0135 - val_acc: 0.5556\n",
      "Epoch 99/100\n",
      "4713/4713 [==============================] - 1s 190us/step - loss: 0.2970 - acc: 0.8672 - val_loss: 4.3660 - val_acc: 0.5556\n",
      "Epoch 100/100\n",
      "4713/4713 [==============================] - 1s 194us/step - loss: 0.2913 - acc: 0.8663 - val_loss: 4.2043 - val_acc: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73bd743850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_std,Y, batch_size=10, epochs=100,validation_data=(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.56      0.38      0.45        13\n",
      "       True       0.56      0.71      0.63        14\n",
      "\n",
      "avg / total       0.56      0.56      0.54        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred= classifier.predict(X_test_std)\n",
    "y_pred =(y_pred>0.5)\n",
    "print classification_report(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_std_, X_test_std_, y_train_std_, y_test_std_ = train_test_split(X_std, Y, test_size=0.33, random_state=42)\n",
    "print(len(X_train_std_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245501285347043\n",
      "0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(max_depth=4, n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_std_,y_train_std_)\n",
    "print(clf.score(X_test_std_, y_test_std_))\n",
    "#print(clf.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 2, n_estimators:  10, score: 0.714, sc: [0.705, 0.717, 0.698, 0.720, 0.730]\n",
      "max_depth: 2, n_estimators:  25, score: 0.759, sc: [0.712, 0.749, 0.695, 0.704, 0.752]\n",
      "max_depth: 2, n_estimators:  50, score: 0.772, sc: [0.744, 0.765, 0.746, 0.762, 0.765]\n",
      "max_depth: 2, n_estimators: 100, score: 0.790, sc: [0.769, 0.778, 0.778, 0.768, 0.775]\n",
      "max_depth: 2, n_estimators: 200, score: 0.808, sc: [0.779, 0.765, 0.804, 0.791, 0.775]\n",
      "max_depth: 3, n_estimators:  10, score: 0.751, sc: [0.715, 0.736, 0.749, 0.733, 0.733]\n",
      "max_depth: 3, n_estimators:  25, score: 0.805, sc: [0.792, 0.772, 0.804, 0.781, 0.791]\n",
      "max_depth: 3, n_estimators:  50, score: 0.810, sc: [0.779, 0.788, 0.820, 0.807, 0.785]\n",
      "max_depth: 3, n_estimators: 100, score: 0.816, sc: [0.798, 0.788, 0.810, 0.810, 0.791]\n",
      "max_depth: 3, n_estimators: 200, score: 0.823, sc: [0.785, 0.794, 0.801, 0.794, 0.781]\n",
      "max_depth: 4, n_estimators:  10, score: 0.760, sc: [0.769, 0.762, 0.756, 0.759, 0.749]\n",
      "max_depth: 4, n_estimators:  25, score: 0.814, sc: [0.798, 0.788, 0.804, 0.801, 0.788]\n",
      "max_depth: 4, n_estimators:  50, score: 0.815, sc: [0.795, 0.788, 0.820, 0.810, 0.781]\n",
      "max_depth: 4, n_estimators: 100, score: 0.825, sc: [0.814, 0.788, 0.823, 0.801, 0.791]\n",
      "max_depth: 4, n_estimators: 200, score: 0.821, sc: [0.798, 0.765, 0.807, 0.801, 0.791]\n",
      "max_depth: 5, n_estimators:  10, score: 0.776, sc: [0.731, 0.765, 0.772, 0.788, 0.730]\n",
      "max_depth: 5, n_estimators:  25, score: 0.817, sc: [0.804, 0.797, 0.810, 0.807, 0.762]\n",
      "max_depth: 5, n_estimators:  50, score: 0.823, sc: [0.795, 0.801, 0.810, 0.823, 0.775]\n",
      "max_depth: 5, n_estimators: 100, score: 0.824, sc: [0.785, 0.785, 0.794, 0.810, 0.781]\n",
      "max_depth: 5, n_estimators: 200, score: 0.820, sc: [0.795, 0.791, 0.785, 0.810, 0.794]\n",
      "max_depth: 6, n_estimators:  10, score: 0.813, sc: [0.766, 0.765, 0.785, 0.807, 0.752]\n",
      "max_depth: 6, n_estimators:  25, score: 0.829, sc: [0.788, 0.801, 0.826, 0.823, 0.781]\n",
      "max_depth: 6, n_estimators:  50, score: 0.830, sc: [0.817, 0.788, 0.826, 0.810, 0.801]\n",
      "max_depth: 6, n_estimators: 100, score: 0.828, sc: [0.804, 0.781, 0.814, 0.823, 0.807]\n",
      "max_depth: 6, n_estimators: 200, score: 0.827, sc: [0.801, 0.772, 0.781, 0.807, 0.788]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#?GradientBoostingClassifier\n",
    "for md in [2,3,4,5,6]:\n",
    "    for ne in [10,25,50,100,200]:\n",
    "        clf = GradientBoostingClassifier(max_depth=md,n_estimators=ne, random_state=42)\n",
    "        clf.fit(X_train_std_,y_train_std_)\n",
    "        scores = cross_val_score(clf,  X_test_std_, y_test_std_, cv=5)\n",
    "        print(\"max_depth: %d, n_estimators: %3d, score: %.3f, sc: [%s]\" % \n",
    "              (md, ne, clf.score(X_test_std_, y_test_std_), ', '.join(map(lambda t: '%.3f' % t,scores.tolist()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential() \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal', input_dim=len(X_std[0]))) \n",
    "classifier.add(Dense(128, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal')) \n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2135 samples, validate on 1053 samples\n",
      "Epoch 1/10\n",
      "2135/2135 [==============================] - 1s 235us/step - loss: 0.3964 - acc: 0.8187 - val_loss: 0.4506 - val_acc: 0.8053\n",
      "Epoch 2/10\n",
      "2135/2135 [==============================] - 0s 213us/step - loss: 0.3863 - acc: 0.8267 - val_loss: 0.4544 - val_acc: 0.8025\n",
      "Epoch 3/10\n",
      "2135/2135 [==============================] - 1s 244us/step - loss: 0.3906 - acc: 0.8197 - val_loss: 0.4482 - val_acc: 0.7987\n",
      "Epoch 4/10\n",
      "2135/2135 [==============================] - 0s 220us/step - loss: 0.3915 - acc: 0.8262 - val_loss: 0.5045 - val_acc: 0.7540\n",
      "Epoch 5/10\n",
      "2135/2135 [==============================] - 0s 217us/step - loss: 0.3849 - acc: 0.8286 - val_loss: 0.4521 - val_acc: 0.7958\n",
      "Epoch 6/10\n",
      "2135/2135 [==============================] - 0s 221us/step - loss: 0.3774 - acc: 0.8253 - val_loss: 0.4620 - val_acc: 0.8063\n",
      "Epoch 7/10\n",
      "2135/2135 [==============================] - 0s 217us/step - loss: 0.3751 - acc: 0.8248 - val_loss: 0.4743 - val_acc: 0.7806\n",
      "Epoch 8/10\n",
      "2135/2135 [==============================] - 0s 221us/step - loss: 0.3841 - acc: 0.8211 - val_loss: 0.4569 - val_acc: 0.7930\n",
      "Epoch 9/10\n",
      "2135/2135 [==============================] - 0s 223us/step - loss: 0.3763 - acc: 0.8267 - val_loss: 0.4681 - val_acc: 0.7977\n",
      "Epoch 10/10\n",
      "2135/2135 [==============================] - 0s 221us/step - loss: 0.3785 - acc: 0.8267 - val_loss: 0.4537 - val_acc: 0.8034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9b72f8850>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_std_,y_train_std_, batch_size=10, epochs=10,validation_data=(X_test_std_, y_test_std_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_std_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-59dab42b5bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_std_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_std_' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred= classifier.predict(X_test_std_)\n",
    "y_pred =(y_pred>0.5)\n",
    "print classification_report(y_pred, y_test_std_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
