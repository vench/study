{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Algorithms \n",
    "\n",
    "1) IE\n",
    "2) K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import set_random_seed \n",
    "import os\n",
    "import random as rn \n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "SEED = 32 \n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "set_random_seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and processed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1906 entries, 0 to 11727\n",
      "Data columns (total 4 columns):\n",
      "id        1906 non-null int64\n",
      "title     1906 non-null object\n",
      "cat_id    1906 non-null int64\n",
      "text2     1906 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 74.5+ KB\n",
      "None\n",
      "(1906, 4)\n",
      "         id                                              title  cat_id  \\\n",
      "821    5008              косово объявило о своей независимости       3   \n",
      "1748  12334  расследование убийства маркелова и бабуровой з...       6   \n",
      "2525  15521       юрия лужкова прочат в премьер-министры крыма       0   \n",
      "\n",
      "                                                  text2  \n",
      "821   location|flag=kosovo|place=приштинакосовопарла...  \n",
      "1748  россиякак сообщил официальный представитель ск...  \n",
      "2525  тема|автономная республика крымдвижение «севас...  \n"
     ]
    }
   ],
   "source": [
    "cat = ['политика', 'россия', 'сша', 'европа', 'экономика', 'общество', 'преступность и право', 'происшествия', 'культура', 'интернет']\n",
    "\n",
    "df = pd.read_pickle('data/dftime_cat.pkl')\n",
    "\n",
    "\n",
    "print(df.info()) \n",
    "print(df.shape)\n",
    "print(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def normal_word(w):\n",
    "    ''' '''\n",
    "    w = w.lower()\n",
    "    info = morph.parse(w)\n",
    "    if(len(info) > 0):\n",
    "        return info[0].normal_form\n",
    "    return w\n",
    "\n",
    "def word_extraction(sentence):  \n",
    "    ''' '''\n",
    "    ignore = {'и','в','а','с','о','к','у','ли', 'можно', 'на', 'снова', 'вот','что','как','без','по','считать','свой',\n",
    "             'который','два','она','это','она','для','тот','если', 'то', 'такой','от', 'он', 'за', 'из','до','быть',\n",
    "             'об', 'этом' , 'так', 'его', 'после', 'вновь', 'все', 'а','с', 'ч', 'п', 'в', 'n', 'я', 'a', 'у', 'м', 'й', \n",
    "              'т', 'h', 'x', 'е', 'и', 'r', 'н', 'g', 'о', 'm', 'c', 'а', 'к', 't', 'l','стало', 'стал'\n",
    "             }    \n",
    "    sentence = re.sub(\"(не)\\s+\", \"\\g<1>\", sentence)\n",
    "    sentence = sentence.replace(\"ё\", \"е\")    \n",
    "    sentence = re.sub(\"[\\d\\.\\-«,%»\\\"\\(\\)—]\", \" \", sentence)\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split() \n",
    "\n",
    "    cleaned_text = []\n",
    "    for w in words:\n",
    "        w =  normal_word(w)\n",
    "        if w not in ignore:\n",
    "            cleaned_text.append(w)        \n",
    "    return cleaned_text\n",
    "\n",
    "def text_to_token(texts):\n",
    "    ''' '''\n",
    "    text_words = []\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    for text in texts:\n",
    "        words = word_extraction(text)\n",
    "        text_words.append(words)\n",
    "        for token in words:\n",
    "            frequency[token] += 1\n",
    "\n",
    "    return [\n",
    "        [token for token in words if frequency[token] > 1]\n",
    "            for words in text_words\n",
    "    ]\n",
    "\n",
    "\n",
    "def processed_text(df):\n",
    "    texts = df['text2']\n",
    "    return text_to_token(texts)\n",
    "\n",
    "\n",
    "texts = processed_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_str = [\" \".join(text) for text in texts]\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2), min_df = 3)  \n",
    "X = vectorizer.fit_transform(texts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_id_vec(id):\n",
    "    v = np.zeros(10)\n",
    "    v[id] = 1\n",
    "    return v\n",
    "Y = df['cat_id'].map(cat_id_vec).values\n",
    "\n",
    "Y_ = df['cat_id'].values\n",
    "Y_label = df['cat_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "\n",
    "def test_cluster(x,y, model):   \n",
    "    model.fit(x)\n",
    "    labels = model.labels_\n",
    "    \n",
    "    scores = []\n",
    "    scores.append(metrics.homogeneity_score(y, labels))\n",
    "    scores.append(metrics.completeness_score(y, labels))\n",
    "    scores.append(metrics.v_measure_score(y, labels))\n",
    "    scores.append(metrics.adjusted_rand_score(y, labels))\n",
    "    scores.append(metrics.adjusted_mutual_info_score(y, labels,\n",
    "                                               average_method='arithmetic'))\n",
    "    scores.append(metrics.silhouette_score(x, labels, metric='sqeuclidean'))\n",
    "    scores.append(len(np.unique(labels)))\n",
    "     \n",
    "    print(\"Homogeneity: %0.3f\" %  scores[0])\n",
    "    print(\"Completeness: %0.3f\" % scores[1])\n",
    "    print(\"V-measure: %0.3f\" % scores[2])\n",
    "    print(\"Adjusted Rand Index: %0.3f\"  % scores[3])\n",
    "    print(\"Adjusted Mutual Information: %0.3f\"  % scores[4])\n",
    "    print(\"Silhouette Coefficient: %0.3f\"  % scores[5])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVG encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def encode_svd(x, k=100): \n",
    "    svd_model = TruncatedSVD(n_components=k, algorithm='randomized', n_iter=100, random_state=SEED)\n",
    "    x1 = svd_model.fit_transform(X) \n",
    "    return x1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.4 s, sys: 53.2 s, total: 1min 48s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_ = encode_svd(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.135\n",
      "Completeness: 0.166\n",
      "V-measure: 0.149\n",
      "Adjusted Rand Index: 0.042\n",
      "Adjusted Mutual Information: 0.139\n",
      "Silhouette Coefficient: 0.065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "m1 = KMeans(n_clusters=10, random_state=SEED)\n",
    "r = test_cluster(X_, Y_, m1)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.135\n",
      "Completeness: 0.192\n",
      "V-measure: 0.159\n",
      "Adjusted Rand Index: 0.018\n",
      "Adjusted Mutual Information: 0.148\n",
      "Silhouette Coefficient: 0.074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster.hierarchical import AgglomerativeClustering\n",
    "m2 = AgglomerativeClustering(n_clusters=10)\n",
    "r = test_cluster(X_, Y_, m2)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.009\n",
      "Completeness: 0.278\n",
      "V-measure: 0.018\n",
      "Adjusted Rand Index: -0.000\n",
      "Adjusted Mutual Information: 0.010\n",
      "Silhouette Coefficient: 0.277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "m3 = DBSCAN()\n",
    "r = test_cluster(X_, Y_, m3)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.395\n",
      "Completeness: 0.179\n",
      "V-measure: 0.246\n",
      "Adjusted Rand Index: 0.015\n",
      "Adjusted Mutual Information: 0.147\n",
      "Silhouette Coefficient: 0.220\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "m4 = AffinityPropagation()\n",
    "r = test_cluster(X_, Y_, m4)\n",
    "results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np \n",
    "\n",
    "class Cluster:\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        ''' '''\n",
    "        self.n = n\n",
    "        self.nodes = set([n])\n",
    "        self.active = True\n",
    "        self.join_n = a = -1 \n",
    "\n",
    "    def merge(self, c):\n",
    "        ''' '''\n",
    "        self.nodes = self.nodes.union(c.nodes)\n",
    "        c.active = False\n",
    "        c.join_n = self.n\n",
    "        \n",
    "    def get_n(self):\n",
    "        if self.join_n == -1:\n",
    "            return self.n\n",
    "        return self.join_n\n",
    "        \n",
    "class HierarchicalClustering:\n",
    "    \n",
    "    def __init__(self, alpha = 1.01, max_iteration = 200, debug= False, delta=0., stop_neg_sum = True, betta = 2., n_clusters=10):\n",
    "        ''' '''\n",
    "        self.alpha = alpha\n",
    "        self.betta = betta\n",
    "        self.max_iteration = max_iteration\n",
    "        self.debug = debug\n",
    "        self._c_all = []\n",
    "        self.delta = delta\n",
    "        self.stop_neg_sum = stop_neg_sum\n",
    "        self.n_clusters= n_clusters\n",
    "        self.labels_ = []\n",
    "    \n",
    "    def score(sefl, x):\n",
    "        ''' '''\n",
    "    \n",
    "    def _get_min(self, M, C):\n",
    "        r = []\n",
    "        for i in range(len(C)):  \n",
    "            for j in range(i,len(C)):\n",
    "                if( M[i][j] <= 0):\n",
    "                    continue\n",
    "                a = C[i].get_n()\n",
    "                b = C[j].get_n()  \n",
    "                if(a == b):\n",
    "                    continue\n",
    "                r.append( M[i][j])    \n",
    "        return min(r)    \n",
    "            \n",
    "    \n",
    "    def fit(self, x):\n",
    "        ''' '''\n",
    "        self._c_all = []\n",
    "        y_ = []\n",
    "        M =  euclidean_distances(x,x)\n",
    "        C = []\n",
    "        size = len(M)\n",
    "        for i in range(size): \n",
    "            C.append( Cluster(i) )\n",
    "        \n",
    "        delta = self.delta\n",
    "        \n",
    "        for i in range(self.max_iteration): \n",
    "            d = np.min(M[M > 0]) * self.alpha \n",
    "            #d = self._get_min(M, C) * self.alpha\n",
    "            if d > delta:\n",
    "                delta = d  \n",
    "            if(self.debug):   \n",
    "                print('delta: %.3f, d: %.3f' % (delta, d))    \n",
    "            M_ = M - delta\n",
    "            ''' join clusters '''\n",
    "            join = False\n",
    "            for i in range(size):  \n",
    "                for j in range(i,size):  \n",
    "                    if(M[i][j] <= 0 or M_[i][j] > 0): # old\n",
    "                        continue\n",
    "                    if i == j:\n",
    "                        continue \n",
    "                    a = C[i].get_n()\n",
    "                    b = C[j].get_n() \n",
    "                    if(a == b):\n",
    "                        continue  \n",
    "                    #if  (C[b].active == False or C[a].active == False):\n",
    "                    #    continue\n",
    "            \n",
    "                    C[a].merge(C[b])\n",
    "                    for s in C[b].nodes:\n",
    "                        C[s].join_n = a\n",
    "                    #sb = C[b][0]\n",
    "                    #C[a][0] = C[a][0].union(sb)  \n",
    "                    #for s in sb:\n",
    "                    #    C[s][1] = C[s][1] - 1\n",
    "                    #    C[s][2] = a \n",
    "                    #C[a][1] = 1 \n",
    "                    #M_[b,:] = 0 \n",
    "                    #M_[:,b] = 0\n",
    "\n",
    "                    #print(M_[b])\n",
    "                    join = True\n",
    "            #print('join', join)        \n",
    "            if join == False:\n",
    "                #break\n",
    "                delta = delta * self.betta\n",
    "                continue\n",
    "            ''' update matrix '''\n",
    "            #delta = d\n",
    "            M =   M_ \n",
    "                    \n",
    "            if len(M[M > 0]) == 0:\n",
    "                print('len(M[M > 0]) == 0')\n",
    "                #print(M_)\n",
    "                break\n",
    "              \n",
    "            #print(C)\n",
    "            y_ = np.zeros(size)\n",
    "            cl = 0\n",
    "            for c in C:\n",
    "                if(c.active == True): \n",
    "                    for i in c.nodes:\n",
    "                        y_[i] = cl\n",
    "                    cl = cl + 1\n",
    "                    \n",
    "            self._c_all.append(y_)  \n",
    "            print('unique len: %d' % len(np.unique(y_)))\n",
    "            if len(np.unique(y_)) <= self.n_clusters:\n",
    "                print('len(np.unique(y_)) == 1')\n",
    "                break\n",
    "            neg,pos = [],[]    \n",
    "            for i in range(size): \n",
    "                for j in range(i,size):\n",
    "                    if(M[i][j] <= 0):\n",
    "                        neg.append(delta + np.abs(M[i][j]))\n",
    "                    else:\n",
    "                        pos.append(M[i][j])    \n",
    "            if(self.debug):\n",
    "                print('Sum pos: %.3f, sum neg: %.3f, Std pos: %.3f, Std neg: %.3f' % \n",
    "                      (sum(pos), sum(neg),np.std(pos), np.std(neg))) \n",
    "            if self.stop_neg_sum and sum(pos) < sum(neg): \n",
    "                print('sum(pos) < sum(neg)')\n",
    "                #break \n",
    "                \n",
    "        self.labels_  = y_      \n",
    "        return y_                \n",
    "        \n",
    "    def print_name(self):\n",
    "        print('Hierarchical clustering')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique len: 1901\n",
      "unique len: 1865\n",
      "unique len: 1089\n",
      "unique len: 56\n",
      "unique len: 4\n",
      "len(np.unique(y_)) == 1\n",
      "Homogeneity: 0.009\n",
      "Completeness: 0.284\n",
      "V-measure: 0.017\n",
      "Adjusted Rand Index: -0.000\n",
      "Adjusted Mutual Information: 0.011\n",
      "Silhouette Coefficient: 0.465\n"
     ]
    }
   ],
   "source": [
    "m5 = HierarchicalClustering(alpha=3.)\n",
    "r = test_cluster(X_, Y_, m5)\n",
    "results.append(r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>V-measure</th>\n",
       "      <th>Adjusted Rand Index</th>\n",
       "      <th>Adjusted Mutual Information</th>\n",
       "      <th>Silhouette Coefficient</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.134564</td>\n",
       "      <td>0.165817</td>\n",
       "      <td>0.148564</td>\n",
       "      <td>0.041994</td>\n",
       "      <td>0.138535</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.135140</td>\n",
       "      <td>0.192284</td>\n",
       "      <td>0.158725</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>0.148039</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009247</td>\n",
       "      <td>0.278023</td>\n",
       "      <td>0.017898</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.277329</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394719</td>\n",
       "      <td>0.178580</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.147046</td>\n",
       "      <td>0.220186</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.283650</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>0.464809</td>\n",
       "      <td>1906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Homogeneity  Completeness  V-measure  Adjusted Rand Index  \\\n",
       "0     0.134564      0.165817   0.148564             0.041994   \n",
       "1     0.135140      0.192284   0.158725             0.017797   \n",
       "2     0.009247      0.278023   0.017898            -0.000271   \n",
       "3     0.394719      0.178580   0.245906             0.014782   \n",
       "4     0.008839      0.283650   0.017144            -0.000136   \n",
       "\n",
       "   Adjusted Mutual Information  Silhouette Coefficient   len  \n",
       "0                     0.138535                0.064892  1906  \n",
       "1                     0.148039                0.074358  1906  \n",
       "2                     0.010441                0.277329  1906  \n",
       "3                     0.147046                0.220186  1906  \n",
       "4                     0.010682                0.464809  1906  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(results, columns=[ \n",
    "    'Homogeneity', \n",
    "    'Completeness', \n",
    "    'V-measure', \n",
    "    'Adjusted Rand Index', 'Adjusted Mutual Information', 'Silhouette Coefficient', 'len'])\n",
    "df2.head(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
